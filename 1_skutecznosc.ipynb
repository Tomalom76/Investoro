{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b0f327-fcfa-4260-8af6-c5ef65a2d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Wczytuję przetworzone dane z pliku 'df_flats_processed.pkl'...\n",
      "Dane wczytane. Liczba ogłoszeń: 1100194\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SEKCJA 1: SETUP I WCZYTANIE DANYCH\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Wczytujemy przetworzone dane\n",
    "print(\"Wczytuję przetworzone dane z pliku 'df_flats_processed.pkl'...\")\n",
    "df_flats = pd.read_pickle('df_flats_processed.pkl')\n",
    "print(f\"Dane wczytane. Liczba ogłoszeń: {len(df_flats)}\")\n",
    "\n",
    "# Definiujemy katalog z artefaktami\n",
    "ARTIFACTS_DIR = '1_Artifacts_Polska'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173666fc-3e7d-4528-812d-4d906fac50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ocena modelu dla miasta: Łódź ---\n",
      "Rozmiar zbioru treningowego: 14518, Rozmiar zbioru testowego: 3630\n",
      "Trenuję model na zbiorze treningowym...\n",
      "Przygotowuję zbiór testowy i dokonuję predykcji...\n",
      "Skuteczność (Accuracy) dla Łódź (na 3614 próbkach testowych):\n",
      "  - Przewidywanie DZIELNICY: 37.66%\n",
      "  - Przewidywanie PODDZIELNICY: 22.66%\n",
      "  - Przewidywanie ULICY: 9.82%\n",
      "\n",
      "--- Ocena modelu dla miasta: Kraków ---\n",
      "Rozmiar zbioru treningowego: 29057, Rozmiar zbioru testowego: 7265\n",
      "Trenuję model na zbiorze treningowym...\n",
      "Przygotowuję zbiór testowy i dokonuję predykcji...\n",
      "Skuteczność (Accuracy) dla Kraków (na 7237 próbkach testowych):\n",
      "  - Przewidywanie DZIELNICY: 39.57%\n",
      "  - Przewidywanie PODDZIELNICY: 12.53%\n",
      "  - Przewidywanie ULICY: 5.15%\n",
      "\n",
      "--- Ocena modelu dla miasta: Warszawa ---\n",
      "Rozmiar zbioru treningowego: 41968, Rozmiar zbioru testowego: 10493\n",
      "Trenuję model na zbiorze treningowym...\n",
      "Przygotowuję zbiór testowy i dokonuję predykcji...\n",
      "Skuteczność (Accuracy) dla Warszawa (na 10460 próbkach testowych):\n",
      "  - Przewidywanie DZIELNICY: 23.23%\n",
      "  - Przewidywanie PODDZIELNICY: 9.50%\n",
      "  - Przewidywanie ULICY: 3.81%\n",
      "\n",
      "--- Ocena modelu dla miasta: Poznań ---\n",
      "Rozmiar zbioru treningowego: 13253, Rozmiar zbioru testowego: 3314\n",
      "Trenuję model na zbiorze treningowym...\n",
      "Przygotowuję zbiór testowy i dokonuję predykcji...\n",
      "Skuteczność (Accuracy) dla Poznań (na 3292 próbkach testowych):\n",
      "  - Przewidywanie DZIELNICY: 32.87%\n",
      "  - Przewidywanie PODDZIELNICY: 15.92%\n",
      "  - Przewidywanie ULICY: 6.80%\n",
      "\n",
      "--- Ocena modelu dla miasta: Wrocław ---\n",
      "Rozmiar zbioru treningowego: 24051, Rozmiar zbioru testowego: 6013\n",
      "Trenuję model na zbiorze treningowym...\n",
      "Przygotowuję zbiór testowy i dokonuję predykcji...\n",
      "Skuteczność (Accuracy) dla Wrocław (na 5985 próbkach testowych):\n",
      "  - Przewidywanie DZIELNICY: 40.94%\n",
      "  - Przewidywanie PODDZIELNICY: 21.20%\n",
      "  - Przewidywanie ULICY: 5.03%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SEKCJA 2: OCENA SKUTECZNOŚCI MODELI (POPRAWIONA)\n",
    "# ==============================================================================\n",
    "\n",
    "# Definicje cech\n",
    "numerical_features = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'BuiltYear']\n",
    "categorical_features = ['BuldingType']\n",
    "text_based_features = ['text_district_id', 'text_subdistrict_id', 'text_street_id']\n",
    "similarity_based_features = ['similar_district_id', 'similar_subdistrict_id', 'similar_street_id']\n",
    "\n",
    "# Słownik do przechowywania wyników\n",
    "evaluation_results = {}\n",
    "\n",
    "# Pętla po miastach, dla których istnieją modele\n",
    "for city_name in ['Łódź', 'Kraków', 'Warszawa', 'Poznań', 'Wrocław']:\n",
    "    model_path = os.path.join(ARTIFACTS_DIR, f'{city_name}_location_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Brak modelu dla {city_name}, pomijam.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Ocena modelu dla miasta: {city_name} ---\")\n",
    "    \n",
    "    # Krok 1: Przygotowanie danych\n",
    "    df_city = df_flats[df_flats['city_name'] == city_name]\n",
    "    full_data = df_city[(df_city['loc_5'] != 0) & (df_city['loc_6'] != 0) & (df_city['loc_7'] != 0)].copy()\n",
    "\n",
    "    if len(full_data) < 100:\n",
    "        print(f\"Zbyt mało danych dla {city_name} do przeprowadzenia rzetelnej oceny.\")\n",
    "        continue\n",
    "\n",
    "    # Krok 2: Podział na zbiór treningowy i testowy (80/20)\n",
    "    try:\n",
    "        train_df, test_df = train_test_split(full_data, test_size=0.2, random_state=42, stratify=full_data['loc_5'])\n",
    "    except ValueError:\n",
    "        train_df, test_df = train_test_split(full_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Rozmiar zbioru treningowego: {len(train_df)}, Rozmiar zbioru testowego: {len(test_df)}\")\n",
    "\n",
    "    # Krok 3: Przygotowanie cech (X) i etykiet (y)\n",
    "    # --- Zbiór treningowy ---\n",
    "    X_train_num = train_df[numerical_features].values\n",
    "    ohe_columns = pd.get_dummies(train_df[categorical_features], prefix='type').columns.tolist()\n",
    "    X_train_cat_dummies = pd.get_dummies(train_df[categorical_features], prefix='type').reindex(columns=ohe_columns, fill_value=0).values\n",
    "    X_train_text = train_df[text_based_features].values\n",
    "    X_train_sim = train_df[similarity_based_features].values\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "    X_train = np.hstack([X_train_num_scaled, X_train_cat_dummies, X_train_text, X_train_sim])\n",
    "\n",
    "    # --- Enkodery i etykiety treningowe ---\n",
    "    encoders = {}\n",
    "    targets_train = {}\n",
    "    target_cols = {'district': 'loc_5', 'subdistrict': 'loc_6', 'street': 'loc_7'}\n",
    "    \n",
    "    for name, col in target_cols.items():\n",
    "        le = LabelEncoder()\n",
    "        targets_train[name] = le.fit_transform(train_df[col])\n",
    "        encoders[name] = le # Zapisujemy cały obiekt enkodera\n",
    "    \n",
    "    # Krok 4: Definicja i trening nowego modelu\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(128, activation='relu')(input_layer)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    output_district = layers.Dense(len(encoders['district'].classes_), activation='softmax', name='district_output')(x)\n",
    "    output_subdistrict = layers.Dense(len(encoders['subdistrict'].classes_), activation='softmax', name='subdistrict_output')(x)\n",
    "    output_street = layers.Dense(len(encoders['street'].classes_), activation='softmax', name='street_output')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=[output_district, output_subdistrict, output_street])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    \n",
    "    print(\"Trenuję model na zbiorze treningowym...\")\n",
    "    model.fit(X_train, list(targets_train.values()), epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "    # Krok 5: Przygotowanie zbioru testowego (tylko znane klasy)\n",
    "    print(\"Przygotowuję zbiór testowy i dokonuję predykcji...\")\n",
    "    \n",
    "    # *** KLUCZOWA ZMIANA TUTAJ ***\n",
    "    # Filtrujemy zbiór testowy, aby zawierał tylko te etykiety, które model zna\n",
    "    known_districts = encoders['district'].classes_\n",
    "    known_subdistricts = encoders['subdistrict'].classes_\n",
    "    known_streets = encoders['street'].classes_\n",
    "    \n",
    "    test_df_filtered = test_df[\n",
    "        test_df['loc_5'].isin(known_districts) &\n",
    "        test_df['loc_6'].isin(known_subdistricts) &\n",
    "        test_df['loc_7'].isin(known_streets)\n",
    "    ].copy()\n",
    "\n",
    "    # Przygotowujemy cechy X dla odfiltrowanego zbioru testowego\n",
    "    X_test_num = test_df_filtered[numerical_features].values\n",
    "    X_test_cat_dummies = pd.get_dummies(test_df_filtered[categorical_features], prefix='type').reindex(columns=ohe_columns, fill_value=0).values\n",
    "    X_test_text = test_df_filtered[text_based_features].values\n",
    "    X_test_sim = test_df_filtered[similarity_based_features].values\n",
    "    \n",
    "    X_test_num_scaled = scaler.transform(X_test_num)\n",
    "    X_test = np.hstack([X_test_num_scaled, X_test_cat_dummies, X_test_text, X_test_sim])\n",
    "\n",
    "    # Przygotowujemy prawdziwe etykiety Y dla odfiltrowanego zbioru\n",
    "    y_test_true_district = encoders['district'].transform(test_df_filtered['loc_5'])\n",
    "    y_test_true_subdistrict = encoders['subdistrict'].transform(test_df_filtered['loc_6'])\n",
    "    y_test_true_street = encoders['street'].transform(test_df_filtered['loc_7'])\n",
    "\n",
    "    # Predykcja\n",
    "    predictions = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Krok 6: Obliczenie skuteczności\n",
    "    pred_district_idx = np.argmax(predictions[0], axis=1)\n",
    "    pred_subdistrict_idx = np.argmax(predictions[1], axis=1)\n",
    "    pred_street_idx = np.argmax(predictions[2], axis=1)\n",
    "\n",
    "    accuracy_district = accuracy_score(y_test_true_district, pred_district_idx)\n",
    "    accuracy_subdistrict = accuracy_score(y_test_true_subdistrict, pred_subdistrict_idx)\n",
    "    accuracy_street = accuracy_score(y_test_true_street, pred_street_idx)\n",
    "    \n",
    "    evaluation_results[city_name] = {\n",
    "        'district_accuracy': accuracy_district,\n",
    "        'subdistrict_accuracy': accuracy_subdistrict,\n",
    "        'street_accuracy': accuracy_street\n",
    "    }\n",
    "\n",
    "    print(f\"Skuteczność (Accuracy) dla {city_name} (na {len(test_df_filtered)} próbkach testowych):\")\n",
    "    print(f\"  - Przewidywanie DZIELNICY: {accuracy_district:.2%}\")\n",
    "    print(f\"  - Przewidywanie PODDZIELNICY: {accuracy_subdistrict:.2%}\")\n",
    "    print(f\"  - Przewidywanie ULICY: {accuracy_street:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64ada6d-ef4e-46d8-8766-833533c97f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Zbiorcze wyniki skuteczności modeli ---\n",
      "\n",
      "          district_accuracy  subdistrict_accuracy  street_accuracy\n",
      "Łódź                 37.66%                22.66%            9.82%\n",
      "Kraków               39.57%                12.53%            5.15%\n",
      "Warszawa             23.23%                 9.50%            3.81%\n",
      "Poznań               32.87%                15.92%            6.80%\n",
      "Wrocław              40.94%                21.20%            5.03%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SEKCJA 3: PODSUMOWANIE EFEKTYWNOŚCI\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n--- Zbiorcze wyniki skuteczności modeli ---\\n\")\n",
    "results_df = pd.DataFrame(evaluation_results).T # Transpozycja dla lepszej czytelności\n",
    "results_df = results_df * 100 # Zamiana na procenty\n",
    "print(results_df.to_string(float_format=\"%.2f%%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62820b66-4540-44d4-b033-cc346ca366a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
