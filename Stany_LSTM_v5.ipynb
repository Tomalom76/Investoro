{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1ef456-8f41-4d09-9b87-925fcdff66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weights (GOOD boosted): {0: 0.9944602272727273, 1: 0.9944602272727273, 2: 1.0169959325973272, 3: 1.1436292613636363}\n",
      "\n",
      "=== Balans klas przed treningiem ===\n",
      "                   count  percent\n",
      "BuildingCondition                \n",
      "AFTER_RENOVATION   22000    25.14\n",
      "DEVELOPER_STATE    22000    25.14\n",
      "FOR_RENOVATION     21513    24.58\n",
      "GOOD               22000    25.14\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: konfiguracja, wczytanie, inżynieria cech, preprocesing (z poprawkami: regex year + imputacja + SVD safe)\n",
    "\n",
    "import os, csv, re, json, gc, math, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# (opcjonalnie) deterministyczność\n",
    "import random, tensorflow as tf\n",
    "SEED = 42\n",
    "np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# 4 źródła\n",
    "FILES = {\n",
    "    'sf_after_renovation.csv': 'AFTER_RENOVATION',\n",
    "    'sf_developer_state.csv' : 'DEVELOPER_STATE',\n",
    "    'sf_for_renovation.csv'  : 'FOR_RENOVATION',\n",
    "    'sf_good.csv'            : 'GOOD',\n",
    "}\n",
    "\n",
    "label_names  = ['AFTER_RENOVATION','DEVELOPER_STATE','FOR_RENOVATION','GOOD']\n",
    "label_to_idx = {name: i for i, name in enumerate(label_names)}\n",
    "\n",
    "# solidny odczyt CSV (jak w v4)\n",
    "def robust_read_records(path, encoding_candidates=('utf-8-sig','utf-8','cp1250','latin1')):\n",
    "    last_err = None\n",
    "    for enc in encoding_candidates:\n",
    "        try:\n",
    "            rows = []\n",
    "            with open(path, 'r', encoding=enc, errors='replace', newline='') as f:\n",
    "                reader = csv.reader(f, delimiter=',', quotechar='\"', escapechar='\\\\')\n",
    "                for row in reader:\n",
    "                    if not row or (len(row) == 1 and not str(row).strip()):\n",
    "                        continue\n",
    "                    rows.append(row)\n",
    "            if not rows: continue\n",
    "            median_len = int(np.median([len(r) for r in rows]))\n",
    "            if median_len < 10: continue\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err: raise last_err\n",
    "    raise RuntimeError(f'Unable to parse CSV: {path}')\n",
    "\n",
    "# mapowanie indeksów kolumn (jak w v4)\n",
    "IDX_MAP = {\n",
    "    'Description': 4,\n",
    "    'Area': 5,\n",
    "    'Price': 6,\n",
    "    'NumberOfRooms': 11,\n",
    "    'BuiltYear': 12,\n",
    "    'BuildingType': 14,\n",
    "    'OfferFrom': 16,\n",
    "    'Floor': 17,\n",
    "    'Floors': 18,\n",
    "    'TypeOfMarket': 19,\n",
    "}\n",
    "IDX_LABEL = 15\n",
    "\n",
    "def extract_required_df(rows, force_label):\n",
    "    sel = {}\n",
    "    for name, idx in IDX_MAP.items():\n",
    "        sel[name] = [(r[idx] if len(r) > idx else None) for r in rows]\n",
    "    out = pd.DataFrame(sel)\n",
    "    out['BuildingCondition'] = [force_label for _ in rows]\n",
    "    return out\n",
    "\n",
    "frames = []\n",
    "for path, label in FILES.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'Brak pliku: {path}')\n",
    "    rows    = robust_read_records(path)\n",
    "    df_part = extract_required_df(rows, force_label=label)\n",
    "    frames.append(df_part)\n",
    "\n",
    "full = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# ——— czyszczenie tekstu ———\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s or \"\"\n",
    "    s = s.lower()\n",
    "    # typowe disclaimers i powtarzalne frazy\n",
    "    patterns = [\n",
    "        r'oferta nie stanowi.*?oferty w rozumieniu kodeksu cywilnego',\n",
    "        r'prosz[ąa] o kontakt.*',\n",
    "        r'tylko u nas.*',\n",
    "        r'nie pobieramy prowizji.*',\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        s = re.sub(p, ' ', s, flags=re.IGNORECASE)\n",
    "    # telefony, e-maile, linki\n",
    "    s = re.sub(r'\\b\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{3,4}\\b', ' ', s)\n",
    "    s = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', s)\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', ' ', s)\n",
    "    # białe znaki\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "full['Description'] = full['Description'].fillna('').astype(str).apply(clean_text)\n",
    "\n",
    "# ——— liczby ———\n",
    "for col in ['Area','Price','NumberOfRooms','Floor','Floors']:\n",
    "    full[col] = pd.to_numeric(full[col], errors='coerce')\n",
    "\n",
    "# ——— bezpieczny parsing roku (regex) zamiast bezpośredniego to_datetime, aby uniknąć ostrzeżeń i niespójności ———\n",
    "def extract_year(val):\n",
    "    s = str(val)\n",
    "    m = re.search(r'(?:18|19|20)\\d{2}', s)\n",
    "    if m:\n",
    "        y = int(m.group(0))\n",
    "        if 1800 <= y <= dt.datetime.now().year + 1:\n",
    "            return y\n",
    "    return np.nan\n",
    "\n",
    "years_rx = full['BuiltYear'].apply(extract_year)\n",
    "full['year'] = years_rx\n",
    "full['year'] = full['year'].fillna(full['year'].median())\n",
    "\n",
    "# ——— inżynieria cech ———\n",
    "# price_per_m2, log1p, winsoryzacja skrajności dla Area/Price/ppm\n",
    "full['price_per_m2'] = np.where((full['Area']>0) & (full['Price']>0), full['Price'] / full['Area'], np.nan)\n",
    "\n",
    "# winsoryzacja 1–99 percentyl\n",
    "for col in ['Area','Price','price_per_m2']:\n",
    "    q01, q99 = full[col].quantile(0.01), full[col].quantile(0.99)\n",
    "    full[col] = full[col].clip(lower=q01, upper=q99)\n",
    "\n",
    "full['log_area']  = np.log1p(full['Area'])\n",
    "full['log_price'] = np.log1p(full['Price'])\n",
    "full['log_ppm']   = np.log1p(full['price_per_m2'])\n",
    "\n",
    "# ——— kategorie ———\n",
    "for col in ['BuildingType','OfferFrom','TypeOfMarket']:\n",
    "    full[col] = full[col].fillna('unknown').astype(str).str.strip().str.lower()\n",
    "\n",
    "def norm_market(v):\n",
    "    v = (v or '').lower()\n",
    "    if 'pierwot' in v: return 'pierwotny'\n",
    "    if 'wtór' in v or 'wtorn' in v: return 'wtórny'\n",
    "    return v if v else 'unknown'\n",
    "full['TypeOfMarket'] = full['TypeOfMarket'].apply(norm_market)\n",
    "\n",
    "# redukcja rzadkich kategorii (top-K)\n",
    "def topk_map(series, k=30):\n",
    "    top = series.value_counts().nlargest(k).index\n",
    "    return series.where(series.isin(top), other='other')\n",
    "\n",
    "full['BuildingType'] = topk_map(full['BuildingType'], k=30)\n",
    "full['OfferFrom']    = topk_map(full['OfferFrom'],    k=30)\n",
    "# TypeOfMarket ma niewiele poziomów — po normalizacji zostawiamy\n",
    "\n",
    "# ——— etykiety ———\n",
    "y_idx = full['BuildingCondition'].map(label_to_idx).astype(int).values\n",
    "y     = to_categorical(y_idx, num_classes=len(label_names))\n",
    "\n",
    "# ——— tokenizacja tekstu ———\n",
    "max_words, max_len = 30000, 250\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"\")\n",
    "tokenizer.fit_on_texts(full['Description'].astype(str))\n",
    "X_text = pad_sequences(tokenizer.texts_to_sequences(full['Description'].astype(str)), maxlen=max_len)\n",
    "\n",
    "# ——— cechy tabelaryczne ———\n",
    "numeric_features = ['Area','Price','NumberOfRooms','Floor','Floors','year',\n",
    "                    'price_per_m2','log_area','log_price','log_ppm']\n",
    "categorical_features = ['BuildingType','OfferFrom','TypeOfMarket']\n",
    "\n",
    "# Imputacja braków w gałęzi numerycznej + skalowanie, aby usunąć NaN-y przed SVD\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipe, numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit-transform do macierzy cech (sparse)\n",
    "X_tab_sparse = preprocessor.fit_transform(full[numeric_features + categorical_features])\n",
    "\n",
    "# Redukcja wymiaru OneHot -> gęste n_comp (SVD) z bezpiecznikiem na liczbę kolumn\n",
    "n_comp = min(256, max(2, X_tab_sparse.shape[1] - 1))\n",
    "svd = TruncatedSVD(n_components=n_comp, random_state=SEED)\n",
    "X_tabular = svd.fit_transform(X_tab_sparse)\n",
    "\n",
    "# Split\n",
    "X_text_train, X_text_test, X_tab_train, X_tab_test, y_train, y_test, y_idx_train, y_idx_test = train_test_split(\n",
    "    X_text, X_tabular, y, y_idx, test_size=0.2, random_state=SEED, stratify=y_idx\n",
    ")\n",
    "\n",
    "# Wagi klas + boost GOOD\n",
    "classes = np.unique(y_idx_train)\n",
    "cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_idx_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "class_weight[label_to_idx['GOOD']] = class_weight.get(label_to_idx['GOOD'], 1.0) * 1.15\n",
    "print(\"\\nClass weights (GOOD boosted):\", class_weight)\n",
    "\n",
    "# Raport rozkładu\n",
    "counts = full['BuildingCondition'].value_counts(dropna=False)\n",
    "perc   = (counts / len(full) * 100).round(2)\n",
    "balance= pd.DataFrame({'count': counts, 'percent': perc}).sort_index()\n",
    "print(\"\\n=== Balans klas przed treningiem ===\")\n",
    "print(balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdba2f9-ca9a-4254-bbf3-a93638c2abf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tabular_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,000,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">135,680</span> │ spatial_dropout1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ tabular_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ tabular_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m200\u001b[0m)          │       \u001b[38;5;34m6,000,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m200\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m135,680\u001b[0m │ spatial_dropout1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m24,704\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │             \u001b[38;5;34m260\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,210,820</span> (23.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,210,820\u001b[0m (23.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,210,436</span> (23.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,210,436\u001b[0m (23.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nTrening v5: BiLSTM+SVD, 25 epok, ES/CKPT po val_macro_f1, RLR po val_loss ...\n",
      "Epoch 1/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4970 - loss: 1.1328\\nval_macro_f1: 0.6318\n",
      "\n",
      "Epoch 1: val_macro_f1 improved from -inf to 0.63182, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1107s\u001b[0m 2s/step - accuracy: 0.4971 - loss: 1.1325 - val_accuracy: 0.6408 - val_loss: 0.8115 - val_macro_f1: 0.6318 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6496 - loss: 0.8519\\nval_macro_f1: 0.6499\n",
      "\n",
      "Epoch 2: val_macro_f1 improved from 0.63182 to 0.64994, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1045s\u001b[0m 2s/step - accuracy: 0.6496 - loss: 0.8519 - val_accuracy: 0.6573 - val_loss: 0.7990 - val_macro_f1: 0.6499 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6848 - loss: 0.8004\\nval_macro_f1: 0.7595\n",
      "\n",
      "Epoch 3: val_macro_f1 improved from 0.64994 to 0.75953, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1067s\u001b[0m 2s/step - accuracy: 0.6849 - loss: 0.8003 - val_accuracy: 0.7644 - val_loss: 0.6245 - val_macro_f1: 0.7595 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7760 - loss: 0.6547\\nval_macro_f1: 0.8155\n",
      "\n",
      "Epoch 4: val_macro_f1 improved from 0.75953 to 0.81546, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1082s\u001b[0m 2s/step - accuracy: 0.7760 - loss: 0.6547 - val_accuracy: 0.8147 - val_loss: 0.5240 - val_macro_f1: 0.8155 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8368 - loss: 0.5365\\nval_macro_f1: 0.8329\n",
      "\n",
      "Epoch 5: val_macro_f1 improved from 0.81546 to 0.83290, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1080s\u001b[0m 2s/step - accuracy: 0.8368 - loss: 0.5364 - val_accuracy: 0.8321 - val_loss: 0.4950 - val_macro_f1: 0.8329 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8629 - loss: 0.4742\\nval_macro_f1: 0.8425\n",
      "\n",
      "Epoch 6: val_macro_f1 improved from 0.83290 to 0.84250, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1082s\u001b[0m 2s/step - accuracy: 0.8630 - loss: 0.4742 - val_accuracy: 0.8420 - val_loss: 0.4884 - val_macro_f1: 0.8425 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8852 - loss: 0.4219\\nval_macro_f1: 0.8447\n",
      "\n",
      "Epoch 7: val_macro_f1 improved from 0.84250 to 0.84469, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1088s\u001b[0m 2s/step - accuracy: 0.8852 - loss: 0.4219 - val_accuracy: 0.8441 - val_loss: 0.4894 - val_macro_f1: 0.8447 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9033 - loss: 0.3776\\nval_macro_f1: 0.8459\n",
      "\n",
      "Epoch 8: val_macro_f1 improved from 0.84469 to 0.84586, saving model to model_best_macro_f1.keras\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1067s\u001b[0m 2s/step - accuracy: 0.9033 - loss: 0.3776 - val_accuracy: 0.8448 - val_loss: 0.4995 - val_macro_f1: 0.8459 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9221 - loss: 0.3301\\nval_macro_f1: 0.8479\n",
      "\n",
      "Epoch 9: val_macro_f1 improved from 0.84586 to 0.84794, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1077s\u001b[0m 2s/step - accuracy: 0.9221 - loss: 0.3301 - val_accuracy: 0.8473 - val_loss: 0.5290 - val_macro_f1: 0.8479 - learning_rate: 5.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9363 - loss: 0.2999\\nval_macro_f1: 0.8478\n",
      "\n",
      "Epoch 10: val_macro_f1 did not improve from 0.84794\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 2s/step - accuracy: 0.9363 - loss: 0.2999 - val_accuracy: 0.8469 - val_loss: 0.5556 - val_macro_f1: 0.8478 - learning_rate: 5.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9427 - loss: 0.2804\\nval_macro_f1: 0.8490\n",
      "\n",
      "Epoch 11: val_macro_f1 improved from 0.84794 to 0.84900, saving model to model_best_macro_f1.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 2s/step - accuracy: 0.9428 - loss: 0.2804 - val_accuracy: 0.8480 - val_loss: 0.5707 - val_macro_f1: 0.8490 - learning_rate: 2.5000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9472 - loss: 0.2671\\nval_macro_f1: 0.8468\n",
      "\n",
      "Epoch 12: val_macro_f1 did not improve from 0.84900\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1063s\u001b[0m 2s/step - accuracy: 0.9472 - loss: 0.2671 - val_accuracy: 0.8461 - val_loss: 0.5857 - val_macro_f1: 0.8468 - learning_rate: 2.5000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9516 - loss: 0.2566\\nval_macro_f1: 0.8451\n",
      "\n",
      "Epoch 13: val_macro_f1 did not improve from 0.84900\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1086s\u001b[0m 2s/step - accuracy: 0.9516 - loss: 0.2566 - val_accuracy: 0.8447 - val_loss: 0.5877 - val_macro_f1: 0.8451 - learning_rate: 1.2500e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9563 - loss: 0.2466\\nval_macro_f1: 0.8468\n",
      "\n",
      "Epoch 14: val_macro_f1 did not improve from 0.84900\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1089s\u001b[0m 2s/step - accuracy: 0.9563 - loss: 0.2466 - val_accuracy: 0.8463 - val_loss: 0.5919 - val_macro_f1: 0.8468 - learning_rate: 1.2500e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9566 - loss: 0.2398\\nval_macro_f1: 0.8442\n",
      "\n",
      "Epoch 15: val_macro_f1 did not improve from 0.84900\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1085s\u001b[0m 2s/step - accuracy: 0.9566 - loss: 0.2398 - val_accuracy: 0.8433 - val_loss: 0.5939 - val_macro_f1: 0.8442 - learning_rate: 6.2500e-05\n",
      "Epoch 16/25\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9577 - loss: 0.2387\\nval_macro_f1: 0.8450\n",
      "\n",
      "Epoch 16: val_macro_f1 did not improve from 0.84900\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1083s\u001b[0m 2s/step - accuracy: 0.9577 - loss: 0.2387 - val_accuracy: 0.8444 - val_loss: 0.5987 - val_macro_f1: 0.8450 - learning_rate: 6.2500e-05\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: model BiLSTM + mocniejsza gałąź tabelaryczna, AdamW, macro-F1 callback i trening\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Bidirectional, Dropout, Dense, Concatenate, SpatialDropout1D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import AdamW  # tf.keras >= 2.11\n",
    "import numpy as np\n",
    "\n",
    "# Callback macro-F1 (jak w v4)\n",
    "class ValMacroF1(Callback):\n",
    "    def __init__(self, val_data, batch_size=1024, verbose=1):\n",
    "        super().__init__()\n",
    "        self.X_text_val, self.X_tab_val, self.y_val = val_data\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        y_pred_proba = self.model.predict([self.X_text_val, self.X_tab_val],\n",
    "                                          batch_size=self.batch_size, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        y_true = np.argmax(self.y_val, axis=1)\n",
    "        macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        logs['val_macro_f1'] = macro_f1\n",
    "        if self.verbose:\n",
    "            print(f\"\\\\nval_macro_f1: {macro_f1:.4f}\")\n",
    "\n",
    "# Tekst: Embedding + SpatialDropout + BiLSTM\n",
    "text_input = Input(shape=(max_len,), name='text_input')\n",
    "emb = Embedding(input_dim=max_words, output_dim=200)(text_input)\n",
    "emb = SpatialDropout1D(0.2)(emb)\n",
    "text_repr = Bidirectional(LSTM(64, recurrent_dropout=0.2))(emb)\n",
    "text_repr = Dropout(0.4)(text_repr)\n",
    "\n",
    "# Tabela: Dense 128->64 z BN i Dropout\n",
    "tabular_input = Input(shape=(X_tab_train.shape[1],), name='tabular_input')\n",
    "tab = Dense(128, activation='relu')(tabular_input)\n",
    "tab = BatchNormalization()(tab)\n",
    "tab = Dropout(0.3)(tab)\n",
    "tab = Dense(64, activation='relu')(tab)\n",
    "tab = BatchNormalization()(tab)\n",
    "tab = Dropout(0.3)(tab)\n",
    "\n",
    "# Fuzja i klasyfikacja\n",
    "x = Concatenate()([text_repr, tab])\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(len(label_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=[text_input, tabular_input], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Kompilacja: AdamW + label smoothing 0.02\n",
    "model.compile(\n",
    "    optimizer=AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "macro_cb = ValMacroF1(val_data=(X_text_test, X_tab_test, y_test), batch_size=1024, verbose=1)\n",
    "es  = EarlyStopping(monitor='val_macro_f1', mode='max', patience=5, restore_best_weights=True, verbose=1)\n",
    "ckp = ModelCheckpoint('model_best_macro_f1.keras', monitor='val_macro_f1', mode='max', save_best_only=True, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "csv = CSVLogger('training_log.csv', append=False)\n",
    "\n",
    "print(\"\\\\nTrening v5: BiLSTM+SVD, 25 epok, ES/CKPT po val_macro_f1, RLR po val_loss ...\")\n",
    "history = model.fit(\n",
    "    [X_text_train, X_tab_train], y_train,\n",
    "    epochs=25,\n",
    "    batch_size=128,\n",
    "    validation_data=([X_text_test, X_tab_test], y_test),\n",
    "    callbacks=[macro_cb, es, ckp, rlr, csv],\n",
    "    class_weight=class_weight\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d7b578-33ce-4609-8be0-be1a84b470c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 135ms/step - accuracy: 0.8453 - loss: 0.5820\n",
      "\\nDokładność na zbiorze testowym: 0.8480\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 131ms/step\n",
      "\\nRaport klasyfikacji na zbiorze testowym:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "AFTER_RENOVATION       0.81      0.82      0.81      4400\n",
      " DEVELOPER_STATE       0.98      0.97      0.97      4400\n",
      "  FOR_RENOVATION       0.88      0.84      0.86      4303\n",
      "            GOOD       0.73      0.77      0.75      4400\n",
      "\n",
      "        accuracy                           0.85     17503\n",
      "       macro avg       0.85      0.85      0.85     17503\n",
      "    weighted avg       0.85      0.85      0.85     17503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: ocena i raport\n",
    "\n",
    "loss, accuracy = model.evaluate([X_text_test, X_tab_test], y_test)\n",
    "print(f\"\\\\nDokładność na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "y_pred_proba = model.predict([X_text_test, X_tab_test])\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\\\nRaport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a135fb-ffbc-49c0-8b81-54c89ca1eb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano: model_lstm_stan.keras, tokenizer.json, preprocessor.joblib, svd_256.joblib, label_mapping.json, columns_for_prediction.joblib\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: zapis artefaktów (model, tokenizer, preprocessor, SVD, mapowania)\n",
    "\n",
    "import joblib, json\n",
    "\n",
    "model.save('model_lstm_stan.keras')\n",
    "\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer.to_json(), ensure_ascii=False))\n",
    "\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "joblib.dump(svd, 'svd_256.joblib')\n",
    "\n",
    "label_mapping = {i: name for i, name in enumerate(label_names)}\n",
    "with open('label_mapping.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({str(k): v for k, v in label_mapping.items()}, f, ensure_ascii=False)\n",
    "\n",
    "columns_for_prediction = numeric_features + categorical_features\n",
    "joblib.dump(columns_for_prediction, 'columns_for_prediction.joblib')\n",
    "\n",
    "print(\"Zapisano: model_lstm_stan.keras, tokenizer.json, preprocessor.joblib, svd_256.joblib, label_mapping.json, columns_for_prediction.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b23a96-f724-4322-ac8e-7f8f89b4adc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam regenerację brakujących parametrów z oryginalnych plików CSV...\n",
      "Dane treningowe wczytane poprawnie.\n",
      "Zapisano median_year.joblib (wartość: 1995.0)\n",
      "Zapisano winsor_params.joblib\n",
      "Zapisano top_k_params.joblib\n",
      "\n",
      "Regeneracja artefaktów zakończona. Możesz teraz uruchomić poprawioną komórkę 5.\n"
     ]
    }
   ],
   "source": [
    "# CELL 4.5 (poprawiony i odporny na błędy CSV): Szybka regeneracja brakujących artefaktów\n",
    "\n",
    "print(\"Rozpoczynam regenerację brakujących parametrów z oryginalnych plików CSV...\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import datetime as dt\n",
    "import csv # Potrzebne dla robust_read_records\n",
    "import os\n",
    "\n",
    "# --- Kopiujemy niezbędne funkcje i definicje z komórki 1 ---\n",
    "\n",
    "# Twoja oryginalna, solidna funkcja do wczytywania CSV\n",
    "def robust_read_records(path, encoding_candidates=('utf-8-sig','utf-8','cp1250','latin1')):\n",
    "    last_err = None\n",
    "    for enc in encoding_candidates:\n",
    "        try:\n",
    "            rows = []\n",
    "            with open(path, 'r', encoding=enc, errors='replace', newline='') as f:\n",
    "                reader = csv.reader(f, delimiter=',', quotechar='\"', escapechar='\\\\')\n",
    "                for row in reader:\n",
    "                    if not row or (len(row) == 1 and not str(row).strip()):\n",
    "                        continue\n",
    "                    rows.append(row)\n",
    "            if not rows: continue\n",
    "            median_len = int(np.median([len(r) for r in rows]))\n",
    "            if median_len < 10: continue\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err: raise last_err\n",
    "    raise RuntimeError(f'Unable to parse CSV: {path}')\n",
    "\n",
    "# Twoje oryginalne mapowanie indeksów\n",
    "IDX_MAP = {\n",
    "    'Description': 4, 'Area': 5, 'Price': 6, 'NumberOfRooms': 11, 'BuiltYear': 12,\n",
    "    'BuildingType': 14, 'OfferFrom': 16, 'Floor': 17, 'Floors': 18, 'TypeOfMarket': 19,\n",
    "}\n",
    "\n",
    "# Twoja oryginalna funkcja do ekstrakcji DataFrame\n",
    "def extract_required_df(rows, force_label):\n",
    "    sel = {}\n",
    "    for name, idx in IDX_MAP.items():\n",
    "        sel[name] = [(r[idx] if len(r) > idx else None) for r in rows]\n",
    "    out = pd.DataFrame(sel)\n",
    "    out['BuildingCondition'] = [force_label for _ in rows]\n",
    "    return out\n",
    "\n",
    "# Funkcja do parsowania roku\n",
    "def extract_year(val):\n",
    "    s = str(val)\n",
    "    m = re.search(r'(?:18|19|20)\\d{2}', s)\n",
    "    if m:\n",
    "        y = int(m.group(0))\n",
    "        if 1800 <= y <= dt.datetime.now().year + 1: return y\n",
    "    return np.nan\n",
    "\n",
    "# Wczytanie i złączenie oryginalnych danych treningowych (używając Twojego kodu)\n",
    "FILES = { 'sf_after_renovation.csv': 'AFTER_RENOVATION', 'sf_developer_state.csv' : 'DEVELOPER_STATE', 'sf_for_renovation.csv'  : 'FOR_RENOVATION', 'sf_good.csv' : 'GOOD', }\n",
    "frames = []\n",
    "for path, label in FILES.items():\n",
    "    if not os.path.exists(path): raise FileNotFoundError(f'Brak pliku: {path}')\n",
    "    rows    = robust_read_records(path)\n",
    "    df_part = extract_required_df(rows, force_label=label)\n",
    "    frames.append(df_part)\n",
    "full = pd.concat(frames, ignore_index=True)\n",
    "print(\"Dane treningowe wczytane poprawnie.\")\n",
    "\n",
    "# --- Przetwarzanie danych w celu wyliczenia i zapisu parametrów ---\n",
    "for col in ['Area','Price','NumberOfRooms','Floor','Floors']: full[col] = pd.to_numeric(full[col], errors='coerce')\n",
    "\n",
    "# 1. Oblicz i zapisz medianę roku\n",
    "full['year'] = full['BuiltYear'].apply(extract_year)\n",
    "median_year_for_imputation = full['year'].median()\n",
    "joblib.dump(median_year_for_imputation, 'median_year.joblib')\n",
    "print(f\"Zapisano median_year.joblib (wartość: {median_year_for_imputation})\")\n",
    "\n",
    "# 2. Oblicz i zapisz parametry winsoryzacji\n",
    "full['price_per_m2'] = np.where((full['Area']>0) & (full['Price']>0), full['Price'] / full['Area'], np.nan)\n",
    "winsor_params = {}\n",
    "for col in ['Area','Price','price_per_m2']:\n",
    "    q01, q99 = full[col].quantile(0.01), full[col].quantile(0.99)\n",
    "    winsor_params[col] = {'lower': q01, 'upper': q99}\n",
    "joblib.dump(winsor_params, 'winsor_params.joblib')\n",
    "print(\"Zapisano winsor_params.joblib\")\n",
    "\n",
    "# 3. Oblicz i zapisz parametry top-K\n",
    "for col in ['BuildingType','OfferFrom','TypeOfMarket']: full[col] = full[col].fillna('unknown').astype(str).str.strip().str.lower()\n",
    "top_k_params = {}\n",
    "def topk_map_and_capture(series, col_name, k=30):\n",
    "    top = series.value_counts().nlargest(k).index\n",
    "    top_k_params[col_name] = list(top)\n",
    "    return series.where(series.isin(top), other='other')\n",
    "\n",
    "_ = topk_map_and_capture(full['BuildingType'], 'BuildingType', k=30)\n",
    "_ = topk_map_and_capture(full['OfferFrom'], 'OfferFrom', k=30)\n",
    "joblib.dump(top_k_params, 'top_k_params.joblib')\n",
    "print(\"Zapisano top_k_params.joblib\")\n",
    "\n",
    "print(\"\\nRegeneracja artefaktów zakończona. Możesz teraz uruchomić poprawioną komórkę 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27727efc-1e8b-4b55-8cd6-df9e80305780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytywanie wszystkich artefaktów...\n",
      "Artefakty wczytane.\n",
      "Wczytywanie surowych danych z saleflats_2024_2025_v2_WITH_PREDICTIONS.csv...\n",
      "Plik wczytany pomyślnie: encoding='utf-8-sig', znaleziono wierszy: 1467263\n",
      "Strukturyzowanie danych dla modelu...\n",
      "Rozpoczynam spójny preprocessing...\n",
      "Preprocessing zakończony.\n",
      "Transformacja danych i predykcja...\n",
      "\u001b[1m717/717\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 653ms/step\n",
      "Predykcja zakończona.\n",
      "\n",
      "Zapisano wynik do: Data_state_LSTM_predicted_full_v4_FINAL.csv (użyto separatora ';')\n",
      "\n",
      "Podgląd wyników (15 pierwszych wierszy):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>88</th>\n",
       "      <th>Predict_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>FOR_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>165</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>173</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>179</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>189</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>208</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>210</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>217</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>224</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>230</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>233</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     88     Predict_State\n",
       "0    99    FOR_RENOVATION\n",
       "1   115  AFTER_RENOVATION\n",
       "2   140              GOOD\n",
       "3   145  AFTER_RENOVATION\n",
       "4   159  AFTER_RENOVATION\n",
       "5   165              GOOD\n",
       "6   173              GOOD\n",
       "7   179  AFTER_RENOVATION\n",
       "8   189              GOOD\n",
       "9   208              GOOD\n",
       "10  210              GOOD\n",
       "11  217  AFTER_RENOVATION\n",
       "12  224  AFTER_RENOVATION\n",
       "13  230              GOOD\n",
       "14  233  AFTER_RENOVATION"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozkład przewidzianych stanów:\n",
      "Predict_State\n",
      "AFTER_RENOVATION    468889\n",
      "DEVELOPER_STATE     465196\n",
      "GOOD                361664\n",
      "FOR_RENOVATION      171513\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CELL 5 (FINALNA, POPRAWIONA WERSJA): Inference z pełną spójnością i poprawnym wyświetlaniem\n",
    "\n",
    "import os, json, re, gc, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# --- Ścieżki do plików ---\n",
    "IN_PATH  = 'saleflats_2024_2025_v2_WITH_PREDICTIONS.csv'\n",
    "OUT_PATH = 'Data_state_LSTM_predicted_full_v4_FINAL.csv' # Nowa nazwa pliku wyjściowego\n",
    "\n",
    "# --- Artefakty z treningu ---\n",
    "MODEL_PATH = 'model_lstm_stan.keras'\n",
    "TOKENIZER_PATH = 'tokenizer.json'\n",
    "PREPROC_PATH = 'preprocessor.joblib'\n",
    "SVD_PATH = 'svd_256.joblib'\n",
    "LABEL_MAP_PATH = 'label_mapping.json'\n",
    "COLS_FOR_PRED_PATH = 'columns_for_prediction.joblib'\n",
    "TOP_K_PATH = 'top_k_params.joblib'\n",
    "WINSOR_PATH = 'winsor_params.joblib'\n",
    "MEDIAN_YEAR_PATH = 'median_year.joblib'\n",
    "MAX_LEN = 250\n",
    "\n",
    "# --- Funkcje pomocnicze ---\n",
    "def robust_read_records(path, encoding_candidates=('utf-8-sig','utf-8','cp1250','latin1')):\n",
    "    last_err = None\n",
    "    for enc in encoding_candidates:\n",
    "        try:\n",
    "            rows = []\n",
    "            with open(path, 'r', encoding=enc, errors='replace', newline='') as f:\n",
    "                reader = csv.reader(f, delimiter=',', quotechar='\"', escapechar='\\\\')\n",
    "                for row in reader:\n",
    "                    if not row or (len(row) == 1 and not str(row).strip()):\n",
    "                        continue\n",
    "                    rows.append(row)\n",
    "            if not rows: continue\n",
    "            median_len = int(np.median([len(r) for r in rows]))\n",
    "            if median_len < 10: continue\n",
    "            print(f\"Plik wczytany pomyślnie: encoding='{enc}', znaleziono wierszy: {len(rows)}\")\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err: raise last_err\n",
    "    raise RuntimeError(f'Unable to parse CSV: {path}')\n",
    "\n",
    "IDX_MAP = {\n",
    "    'Description': 4, 'Area': 5, 'Price': 6, 'NumberOfRooms': 11, 'BuiltYear': 12,\n",
    "    'BuildingType': 14, 'OfferFrom': 16, 'Floor': 17, 'Floors': 18, 'TypeOfMarket': 19,\n",
    "}\n",
    "\n",
    "def extract_required_df_from_rows(rows):\n",
    "    sel = {}\n",
    "    for name, idx in IDX_MAP.items():\n",
    "        sel[name] = [(r[idx] if len(r) > idx else None) for r in rows]\n",
    "    return pd.DataFrame(sel)\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = (s or \"\").lower()\n",
    "    patterns = [r'oferta nie stanowi.*?oferty w rozumieniu kodeksu cywilnego', r'prosz[ąa] o kontakt.*', r'tylko u nas.*', r'nie pobieramy prowizji.*']\n",
    "    for p in patterns: s = re.sub(p, ' ', s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r'\\b\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{3,4}\\b', ' ', s)\n",
    "    s = re.sub(r'[\\w\\.-]+@[\\w\\.-]+', ' ', s)\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def extract_year(val):\n",
    "    s = str(val)\n",
    "    m = re.search(r'(?:18|19|20)\\d{2}', s)\n",
    "    if m:\n",
    "        y = int(m.group(0))\n",
    "        if 1800 <= y <= dt.datetime.now().year + 1: return y\n",
    "    return np.nan\n",
    "\n",
    "def norm_market(v):\n",
    "    v = (v or '').lower()\n",
    "    if 'pierwot' in v: return 'pierwotny'\n",
    "    if 'wtór' in v or 'wtorn' in v: return 'wtórny'\n",
    "    return v if v else 'unknown'\n",
    "\n",
    "# --- Główny skrypt predykcyjny ---\n",
    "print(\"Wczytywanie wszystkich artefaktów...\")\n",
    "with open(TOKENIZER_PATH, 'r', encoding='utf-8') as f: tokenizer_data = json.load(f)\n",
    "tokenizer = tokenizer_from_json(json.dumps(tokenizer_data) if isinstance(tokenizer_data, dict) else tokenizer_data)\n",
    "preprocessor = joblib.load(PREPROC_PATH)\n",
    "svd = joblib.load(SVD_PATH)\n",
    "columns_for_prediction = joblib.load(COLS_FOR_PRED_PATH)\n",
    "label_map = {int(k): v for k, v in json.load(open(LABEL_MAP_PATH, 'r', encoding='utf-8')).items()}\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "top_k_params = joblib.load(TOP_K_PATH)\n",
    "winsor_params = joblib.load(WINSOR_PATH)\n",
    "median_year = joblib.load(MEDIAN_YEAR_PATH)\n",
    "print(\"Artefakty wczytane.\")\n",
    "\n",
    "print(f\"Wczytywanie surowych danych z {IN_PATH}...\")\n",
    "all_rows = robust_read_records(IN_PATH)\n",
    "header = all_rows[0]\n",
    "data_rows = all_rows[1:]\n",
    "\n",
    "df_src = pd.DataFrame(data_rows)\n",
    "df_src.columns = header[:len(df_src.columns)]\n",
    "\n",
    "print(\"Strukturyzowanie danych dla modelu...\")\n",
    "infer_df = extract_required_df_from_rows(data_rows)\n",
    "\n",
    "print(\"Rozpoczynam spójny preprocessing...\")\n",
    "infer_df['Description'] = infer_df['Description'].fillna('').astype(str).apply(clean_text)\n",
    "for col in ['Area','Price','NumberOfRooms','Floor','Floors']: infer_df[col] = pd.to_numeric(infer_df[col], errors='coerce')\n",
    "infer_df['year'] = infer_df['BuiltYear'].apply(extract_year)\n",
    "infer_df['year'] = infer_df['year'].fillna(median_year)\n",
    "infer_df['price_per_m2'] = np.where((infer_df['Area']>0) & (infer_df['Price']>0), infer_df['Price']/infer_df['Area'], np.nan)\n",
    "for col, params in winsor_params.items():\n",
    "    if col in infer_df.columns: infer_df[col] = infer_df[col].clip(lower=params['lower'], upper=params['upper'])\n",
    "infer_df['log_area']  = np.log1p(infer_df['Area'])\n",
    "infer_df['log_price'] = np.log1p(infer_df['Price'])\n",
    "infer_df['log_ppm']   = np.log1p(infer_df['price_per_m2'])\n",
    "for col in ['BuildingType','OfferFrom','TypeOfMarket']: infer_df[col] = infer_df[col].fillna('unknown').astype(str).str.strip().str.lower()\n",
    "infer_df['TypeOfMarket'] = infer_df['TypeOfMarket'].apply(norm_market)\n",
    "for col, top_list in top_k_params.items():\n",
    "    if col in infer_df.columns: infer_df[col] = infer_df[col].where(infer_df[col].isin(top_list), 'other')\n",
    "print(\"Preprocessing zakończony.\")\n",
    "\n",
    "print(\"Transformacja danych i predykcja...\")\n",
    "X_text = pad_sequences(tokenizer.texts_to_sequences(infer_df['Description'].astype(str)), maxlen=MAX_LEN)\n",
    "X_tab_sparse = preprocessor.transform(infer_df[columns_for_prediction])\n",
    "X_tabular = svd.transform(X_tab_sparse)\n",
    "y_pred_proba = model.predict([X_text, X_tabular], batch_size=2048, verbose=1)\n",
    "y_pred_idx = np.argmax(y_pred_proba, axis=1)\n",
    "predict_state = [label_map.get(i, 'UNKNOWN') for i in y_pred_idx]\n",
    "print(\"Predykcja zakończona.\")\n",
    "\n",
    "df_out = df_src.copy()\n",
    "df_out['Predict_State'] = predict_state\n",
    "df_out.to_csv(OUT_PATH, index=False, encoding='utf-8-sig', sep=';')\n",
    "print(f\"\\nZapisano wynik do: {OUT_PATH} (użyto separatora ';')\")\n",
    "\n",
    "# --- POPRAWIONA SEKCJA WYŚWIETLANIA WYNIKÓW ---\n",
    "print(\"\\nPodgląd wyników (15 pierwszych wierszy):\")\n",
    "pd.set_option('display.max_colwidth', 50) # Ograniczamy szerokość dla czytelności podglądu\n",
    "\n",
    "# Bezpieczne znajdowanie kolumn po nazwach z nagłówka\n",
    "def find_col_by_name(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "price_col_name = find_col_by_name(df_out, ['Price', 'price', 'Cena'])\n",
    "area_col_name = find_col_by_name(df_out, ['Area', 'area', 'Powierzchnia'])\n",
    "saleid_col_name = find_col_by_name(df_out, ['SaleId', 'id']) or df_out.columns[0] # Jeśli nie ma, bierz pierwszą\n",
    "\n",
    "preview_cols = [c for c in [saleid_col_name, price_col_name, area_col_name, 'Predict_State'] if c is not None]\n",
    "\n",
    "# Sprawdź, czy lista kolumn nie jest pusta\n",
    "if preview_cols:\n",
    "    display(df_out[preview_cols].head(15))\n",
    "else:\n",
    "    print(\"Nie udało się znaleźć kolumn do wyświetlenia podglądu.\")\n",
    "\n",
    "print(\"\\nRozkład przewidzianych stanów:\")\n",
    "print(df_out['Predict_State'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34796697-14db-4a5e-b9a9-a540bb55b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytywanie finalnego pliku z wynikami: Data_state_LSTM_predicted_full_v4_FINAL.csv\n",
      "Wczytano 1467262 wierszy.\n",
      "\n",
      "Rozkład przewidzianych stanów w pliku wynikowym:\n",
      "Predict_State\n",
      "AFTER_RENOVATION    468889\n",
      "DEVELOPER_STATE     465196\n",
      "GOOD                361664\n",
      "FOR_RENOVATION      171513\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Reprezentatywne przykłady dla każdej kategorii:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>88</th>\n",
       "      <th>Mieszkanie trzypokojowe na sprzedaż</th>\n",
       "      <th>Predict_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4748163</td>\n",
       "      <td>Mieszkanie, Opole, Zaodrze, 47 m²</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3612967</td>\n",
       "      <td>Takiej panoramy Krakowa nie widzi się codziennie.</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3873884</td>\n",
       "      <td>3-pokojowe mieszkanie 70m2 + balkon Bezpośrednio</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2753375</td>\n",
       "      <td>Stylowe 2pokoje z widokiem na las i zachody słońca</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5176968</td>\n",
       "      <td>Nowe mieszkanie Działki Leśne, ul. Poznańska 1</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3514076</td>\n",
       "      <td>Zgarnij dod GRUDNIOWY Rabat_HALA_Komórka_GOTOWE</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>686572</td>\n",
       "      <td>Mieszkanie trzypokojowe na sprzedaż</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4463074</td>\n",
       "      <td>Mieszkanie</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4838395</td>\n",
       "      <td>Przestronne mieszkanie w centrum Łeby</td>\n",
       "      <td>FOR_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4003061</td>\n",
       "      <td>Mieszkanie, Kraków, Prądnik Biały, 58 m²</td>\n",
       "      <td>FOR_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4583900</td>\n",
       "      <td>REZERWACJA Bykowina z dwoma pokojami i oddzielną kuchnią</td>\n",
       "      <td>FOR_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2421878</td>\n",
       "      <td>Mieszkanie trzypokojowe na sprzedaż</td>\n",
       "      <td>FOR_RENOVATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5167236</td>\n",
       "      <td>Przestronne M4 piękna panorama duży balkon</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>712783</td>\n",
       "      <td>Mieszkanie, Gdynia, Śródmieście, 26 m²</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4189757</td>\n",
       "      <td>Rezerwacja blisko centrum - os. Dąbrowskiego -</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4465452</td>\n",
       "      <td>Mieszkanie, ul. Narbutta</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         88                       Mieszkanie trzypokojowe na sprzedaż     Predict_State\n",
       "0   4748163                         Mieszkanie, Opole, Zaodrze, 47 m²  AFTER_RENOVATION\n",
       "1   3612967         Takiej panoramy Krakowa nie widzi się codziennie.  AFTER_RENOVATION\n",
       "2   3873884          3-pokojowe mieszkanie 70m2 + balkon Bezpośrednio  AFTER_RENOVATION\n",
       "3   2753375        Stylowe 2pokoje z widokiem na las i zachody słońca  AFTER_RENOVATION\n",
       "4   5176968            Nowe mieszkanie Działki Leśne, ul. Poznańska 1   DEVELOPER_STATE\n",
       "5   3514076           Zgarnij dod GRUDNIOWY Rabat_HALA_Komórka_GOTOWE   DEVELOPER_STATE\n",
       "6    686572                       Mieszkanie trzypokojowe na sprzedaż   DEVELOPER_STATE\n",
       "7   4463074                                                Mieszkanie   DEVELOPER_STATE\n",
       "8   4838395                     Przestronne mieszkanie w centrum Łeby    FOR_RENOVATION\n",
       "9   4003061                  Mieszkanie, Kraków, Prądnik Biały, 58 m²    FOR_RENOVATION\n",
       "10  4583900  REZERWACJA Bykowina z dwoma pokojami i oddzielną kuchnią    FOR_RENOVATION\n",
       "11  2421878                       Mieszkanie trzypokojowe na sprzedaż    FOR_RENOVATION\n",
       "12  5167236                Przestronne M4 piękna panorama duży balkon              GOOD\n",
       "13   712783                    Mieszkanie, Gdynia, Śródmieście, 26 m²              GOOD\n",
       "14  4189757            Rezerwacja blisko centrum - os. Dąbrowskiego -              GOOD\n",
       "15  4465452                                  Mieszkanie, ul. Narbutta              GOOD"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyświetlono 16 przykładów.\n"
     ]
    }
   ],
   "source": [
    "# CELL 6 (FINALNA ANALIZA): Wczytanie i analiza poprawnie wygenerowanego pliku\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "PATH = 'Data_state_LSTM_predicted_full_v4_FINAL.csv'\n",
    "\n",
    "# Ustawienia wyświetlania\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "try:\n",
    "    print(f\"Wczytywanie finalnego pliku z wynikami: {PATH}\")\n",
    "    # Wczytujemy poprawny plik, pamiętając o separatorze ';'\n",
    "    df = pd.read_csv(PATH, sep=';', low_memory=False)\n",
    "    print(f\"Wczytano {len(df)} wierszy.\")\n",
    "\n",
    "    # --- Krok 1: Wyświetl rozkład przewidzianych stanów ---\n",
    "    print(\"\\nRozkład przewidzianych stanów w pliku wynikowym:\")\n",
    "    print(df['Predict_State'].value_counts())\n",
    "    \n",
    "    # --- Krok 2: Wyświetl reprezentatywne próbki ---\n",
    "    print(\"\\nReprezentatywne przykłady dla każdej kategorii:\")\n",
    "    \n",
    "    # Funkcja do bezpiecznego znajdowania nazw kolumn (na wszelki wypadek)\n",
    "    def pick_col(df, candidates):\n",
    "        # Sprawdzamy też nazwy z małych liter\n",
    "        candidates_lower = [str(c).lower() for c in candidates]\n",
    "        df_cols_lower = {c.lower(): c for c in df.columns}\n",
    "        \n",
    "        for cand_lower in candidates_lower:\n",
    "            if cand_lower in df_cols_lower:\n",
    "                return df_cols_lower[cand_lower]\n",
    "        return None # Zwróć None, jeśli nic nie znaleziono\n",
    "\n",
    "    # Identyfikujemy kolumny, których nazwy mogą się różnić\n",
    "    # Używamy oryginalnych nazw z IDX_MAP oraz potencjalnych alternatyw\n",
    "    saleid_col = pick_col(df, ['SaleId', 'id', df.columns[0]])\n",
    "    title_col = pick_col(df, ['Title', 'tytuł', 'Mieszkanie trzypokojowe na sprzedaż'])\n",
    "    price_col = pick_col(df, ['Price', 'Cena'])\n",
    "    area_col = pick_col(df, ['Area', 'Powierzchnia'])\n",
    "    loc_col = pick_col(df, ['Predicted_Loc']) \n",
    "    state_col = 'Predict_State'\n",
    "\n",
    "    # Zbieramy próbki\n",
    "    samples_list = []\n",
    "    target_states = df[state_col].unique()\n",
    "    for state in target_states:\n",
    "        # Bierzemy po 4 losowe próbki dla każdego stanu\n",
    "        samples_list.append(df[df[state_col] == state].sample(n=min(4, len(df[df[state_col] == state])), random_state=42))\n",
    "\n",
    "    if samples_list:\n",
    "        df_samples = pd.concat(samples_list).sort_values(by=state_col).reset_index(drop=True)\n",
    "        \n",
    "        # Wyświetlanie\n",
    "        display_cols = [c for c in [saleid_col, title_col, price_col, area_col, loc_col, state_col] if c is not None]\n",
    "        display(df_samples[display_cols])\n",
    "        print(f\"\\nWyświetlono {len(df_samples)} przykładów.\")\n",
    "    else:\n",
    "        print(\"Nie udało się znaleźć próbek do wyświetlenia.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"BŁĄD: Nie znaleziono pliku '{PATH}'. Upewnij się, że komórka 5 została pomyślnie uruchomiona i plik istnieje.\")\n",
    "except Exception as e:\n",
    "    print(f\"Wystąpił nieoczekiwany błąd: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee10e53-8a7f-4271-a6a9-0e8f431d36a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
