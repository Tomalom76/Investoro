{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e152d3-0718-4f8b-a46b-6d6a65b37b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ai\\AppData\\Local\\miniconda3\\envs\\projekt_stan\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Wczytywanie danych ---\n",
      "Pliki wczytane pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 1: IMPORT I WCZYTANIE DANYCH ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Concatenate, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)\n",
    "\n",
    "print(\"--- Wczytywanie danych ---\")\n",
    "try:\n",
    "    df_main_raw = pd.read_csv('saleflats_mazowieckie_c.csv', sep=',', header=None, on_bad_lines='skip', low_memory=False)\n",
    "    # Wczytujemy nasz nowy, zweryfikowany słownik\n",
    "    df_slownik = pd.read_csv('slownik_finalny_z_hierarchia.csv', sep=';')\n",
    "    print(\"Pliki wczytane pomyślnie.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"BŁĄD: Nie znaleziono pliku: {e.filename}.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6581b0-c975-4edc-876a-cae03c6e33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Przygotowanie danych do modelu ---\n",
      "\n",
      "\n",
      "Łączenie ofert z danymi ze słownika...\n",
      "Liczba ofert po połączeniu ze słownikiem: 8066\n",
      "Finalny zbiór danych gotowy. Wiersze: 8066\n",
      "\n",
      "Wzbogacanie opisów o tytuł i nazwy lokalizacji w celu wzmocnienia sygnału...\n",
      "\n",
      "Problem przygotowany do modelowania:\n",
      " - Liczba klas (dzielnice): 18 -> ['Bemowo' 'Białołęka' 'Bielany' 'Mokotów' 'Ochota']...\n",
      " - Liczba klas (ulice): 661\n",
      "\n",
      "Dane podzielone na zbiory treningowe i walidacyjne.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 2: PRZYGOTOWANIE DANYCH -- Z WZBOGACANIEM OPISU I NOWYMI CECHAMI ===\n",
    "print(\"--- Przygotowanie danych do modelu ---\\n\")\n",
    "\n",
    "# --- 2.1: Przygotowanie danych z ofert ---\n",
    "df_main = df_main_raw.copy()\n",
    "df_main.columns = [i for i in range(53)] + ['WojewodztwoID', 'PowiatID', 'GminaID', 'RodzajGminyID', 'MiastoID', 'DzielnicaID', 'UlicaID']\n",
    "\n",
    "# === ZMIANA: Dodano mapowanie dla 'Title' i 'BuiltYear' ===\n",
    "# !!! WAŻNE: Sprawdź, czy indeksy (3 i 39) są poprawne dla Twojego pliku CSV !!!\n",
    "main_cols_map = {\n",
    "    0: 'SaleId',\n",
    "    3: 'Title',\n",
    "    4: 'Description',\n",
    "    5: 'Area',\n",
    "    6: 'Price',\n",
    "    12: 'BuiltYear',     # <-- POPRAWNIE\n",
    "    17: 'NumberOfRooms',\n",
    "    35: 'Floor',\n",
    "    36: 'Floors'\n",
    "}\n",
    "df_main.rename(columns=main_cols_map, inplace=True)\n",
    "\n",
    "# === ZMIANA: Dodano 'BuiltYear' do cech numerycznych ===\n",
    "numeric_features = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'BuiltYear']\n",
    "text_features = ['Title', 'Description'] # <-- DODANO dla przejrzystości\n",
    "id_features = ['UlicaID']\n",
    "\n",
    "for col in numeric_features + id_features:\n",
    "    df_main[col] = pd.to_numeric(df_main[col], errors='coerce')\n",
    "\n",
    "# Upewnijmy się, że kluczowe kolumny tekstowe nie są puste i zastąpmy ewentualne NaN\n",
    "for col in text_features:\n",
    "    df_main[col] = df_main[col].fillna('')\n",
    "\n",
    "# Usuwamy wiersze, gdzie brakuje kluczowych danych numerycznych lub ID\n",
    "df_main.dropna(subset=numeric_features + id_features, inplace=True)\n",
    "df_main['UlicaID'] = df_main['UlicaID'].astype(int)\n",
    "\n",
    "# --- 2.2: Łączenie ofert ze słownikiem ---\n",
    "print(\"\\nŁączenie ofert z danymi ze słownika...\")\n",
    "df_merged = pd.merge(df_main, df_slownik, on='UlicaID', how='inner')\n",
    "print(f\"Liczba ofert po połączeniu ze słownikiem: {len(df_merged)}\")\n",
    "\n",
    "if len(df_merged) == 0:\n",
    "    raise ValueError(\"Połączenie danych nie dało żadnych wyników.\")\n",
    "\n",
    "df_model_ready = df_merged.copy()\n",
    "print(f\"Finalny zbiór danych gotowy. Wiersze: {len(df_model_ready)}\")\n",
    "\n",
    "\n",
    "# --- 2.3: Przygotowanie Danych Wejściowych (X) ---\n",
    "# ==============================================================================\n",
    "# === ZMIANA: Wzbogacanie opisu o TYTUŁ i nazwy lokalizacji ===\n",
    "# ==============================================================================\n",
    "print(\"\\nWzbogacanie opisów o tytuł i nazwy lokalizacji w celu wzmocnienia sygnału...\")\n",
    "df_model_ready['description_enriched'] = df_model_ready['Title'] + \" \" + df_model_ready['Description'] + \" \" + df_model_ready['Dzielnica_Name'] + \" \" + df_model_ready['Ulica_Name']\n",
    "\n",
    "def clean_text(text): return re.sub(r'[^a-ząęółśżźćń ]', '', str(text).lower())\n",
    "\n",
    "# Używamy teraz nowej, wzbogaconej kolumny do nauki tokenizera\n",
    "df_model_ready['description_clean'] = df_model_ready['description_enriched'].apply(clean_text)\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "MAX_WORDS, MAX_LEN = 20000, 250\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(df_model_ready['description_clean'])\n",
    "X_text = pad_sequences(tokenizer.texts_to_sequences(df_model_ready['description_clean']), maxlen=MAX_LEN)\n",
    "\n",
    "df_model_ready['Price_per_sqm'] = df_model_ready['Price'] / df_model_ready['Area']\n",
    "df_model_ready['Price_per_sqm'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# === ZMIANA: Dodano 'BuiltYear' do listy cech dla pipelinu numerycznego ===\n",
    "numeric_features_cols = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'BuiltYear', 'Price_per_sqm']\n",
    "numeric_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "X_numeric = numeric_pipeline.fit_transform(df_model_ready[numeric_features_cols])\n",
    "\n",
    "# --- 2.4: Przygotowanie Danych Wyjściowych (y) ---\n",
    "le_dzielnica = LabelEncoder()\n",
    "y_dzielnica = le_dzielnica.fit_transform(df_model_ready['Dzielnica_Name'])\n",
    "num_classes_dzielnica = len(le_dzielnica.classes_)\n",
    "le_ulica = LabelEncoder()\n",
    "y_ulica = le_ulica.fit_transform(df_model_ready['Ulica_Name'])\n",
    "num_classes_ulica = len(le_ulica.classes_)\n",
    "\n",
    "print(f\"\\nProblem przygotowany do modelowania:\")\n",
    "print(f\" - Liczba klas (dzielnice): {num_classes_dzielnica} -> {le_dzielnica.classes_[:5]}...\")\n",
    "print(f\" - Liczba klas (ulice): {num_classes_ulica}\")\n",
    "\n",
    "train_indices, val_indices = train_test_split(range(len(df_model_ready)), test_size=0.2, random_state=42, stratify=y_dzielnica)\n",
    "X_train_text, X_val_text = X_text[train_indices], X_text[val_indices]\n",
    "X_train_num, X_val_num = X_numeric[train_indices], X_numeric[val_indices]\n",
    "y_train_dzielnica, y_val_dzielnica = y_dzielnica[train_indices], y_dzielnica[val_indices]\n",
    "y_train_ulica, y_val_ulica = y_ulica[train_indices], y_ulica[val_indices]\n",
    "\n",
    "print(\"\\nDane podzielone na zbiory treningowe i walidacyjne.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d050d6a7-aa81-4891-8814-80bfb7a75e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numeric_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│                               │                           │                 │ numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_dzielnica (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_ulica (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">661</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">169,877</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m2,560,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m131,584\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numeric_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m135\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│                               │                           │                 │ numeric_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m17,408\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │          \u001b[38;5;34m33,024\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_dzielnica (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                │           \u001b[38;5;34m1,170\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ output_ulica (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m661\u001b[0m)               │         \u001b[38;5;34m169,877\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,921,319</span> (11.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,921,319\u001b[0m (11.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,921,319</span> (11.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,921,319\u001b[0m (11.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynam trening modelu hierarchicznego...\n",
      "Epoch 1/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 393ms/step - loss: 5.4596 - output_dzielnica_accuracy: 0.2667 - output_dzielnica_loss: 2.4988 - output_ulica_accuracy: 0.0816 - output_ulica_loss: 5.9209 - val_loss: 3.5376 - val_output_dzielnica_accuracy: 0.5892 - val_output_dzielnica_loss: 1.2953 - val_output_ulica_accuracy: 0.1648 - val_output_ulica_loss: 4.4905 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 369ms/step - loss: 3.2336 - output_dzielnica_accuracy: 0.6756 - output_dzielnica_loss: 1.0819 - output_ulica_accuracy: 0.1759 - output_ulica_loss: 4.3029 - val_loss: 2.4042 - val_output_dzielnica_accuracy: 0.8309 - val_output_dzielnica_loss: 0.5542 - val_output_ulica_accuracy: 0.1958 - val_output_ulica_loss: 3.7026 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 366ms/step - loss: 2.2555 - output_dzielnica_accuracy: 0.8426 - output_dzielnica_loss: 0.5010 - output_ulica_accuracy: 0.2445 - output_ulica_loss: 3.5093 - val_loss: 1.9207 - val_output_dzielnica_accuracy: 0.8941 - val_output_dzielnica_loss: 0.3756 - val_output_ulica_accuracy: 0.3600 - val_output_ulica_loss: 3.0973 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 363ms/step - loss: 1.8125 - output_dzielnica_accuracy: 0.8910 - output_dzielnica_loss: 0.3547 - output_ulica_accuracy: 0.3611 - output_ulica_loss: 2.9153 - val_loss: 1.5578 - val_output_dzielnica_accuracy: 0.9486 - val_output_dzielnica_loss: 0.2253 - val_output_ulica_accuracy: 0.4542 - val_output_ulica_loss: 2.6700 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 364ms/step - loss: 1.4343 - output_dzielnica_accuracy: 0.9352 - output_dzielnica_loss: 0.2228 - output_ulica_accuracy: 0.4383 - output_ulica_loss: 2.4226 - val_loss: 1.2964 - val_output_dzielnica_accuracy: 0.9653 - val_output_dzielnica_loss: 0.1244 - val_output_ulica_accuracy: 0.5397 - val_output_ulica_loss: 2.3466 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 366ms/step - loss: 1.1485 - output_dzielnica_accuracy: 0.9589 - output_dzielnica_loss: 0.1363 - output_ulica_accuracy: 0.5210 - output_ulica_loss: 2.0243 - val_loss: 1.1131 - val_output_dzielnica_accuracy: 0.9882 - val_output_dzielnica_loss: 0.0845 - val_output_ulica_accuracy: 0.5954 - val_output_ulica_loss: 2.0590 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 367ms/step - loss: 0.9700 - output_dzielnica_accuracy: 0.9681 - output_dzielnica_loss: 0.0950 - output_ulica_accuracy: 0.5689 - output_ulica_loss: 1.7501 - val_loss: 0.9873 - val_output_dzielnica_accuracy: 0.9944 - val_output_dzielnica_loss: 0.0485 - val_output_ulica_accuracy: 0.6400 - val_output_ulica_loss: 1.8811 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 367ms/step - loss: 0.8352 - output_dzielnica_accuracy: 0.9781 - output_dzielnica_loss: 0.0747 - output_ulica_accuracy: 0.6170 - output_ulica_loss: 1.5209 - val_loss: 0.9015 - val_output_dzielnica_accuracy: 0.9975 - val_output_dzielnica_loss: 0.0393 - val_output_ulica_accuracy: 0.6834 - val_output_ulica_loss: 1.7286 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 372ms/step - loss: 0.7236 - output_dzielnica_accuracy: 0.9829 - output_dzielnica_loss: 0.0589 - output_ulica_accuracy: 0.6532 - output_ulica_loss: 1.3295 - val_loss: 0.8729 - val_output_dzielnica_accuracy: 0.9938 - val_output_dzielnica_loss: 0.0420 - val_output_ulica_accuracy: 0.7119 - val_output_ulica_loss: 1.6663 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 369ms/step - loss: 0.6550 - output_dzielnica_accuracy: 0.9853 - output_dzielnica_loss: 0.0484 - output_ulica_accuracy: 0.6688 - output_ulica_loss: 1.2132 - val_loss: 0.8355 - val_output_dzielnica_accuracy: 0.9969 - val_output_dzielnica_loss: 0.0348 - val_output_ulica_accuracy: 0.7534 - val_output_ulica_loss: 1.6062 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 372ms/step - loss: 0.5943 - output_dzielnica_accuracy: 0.9853 - output_dzielnica_loss: 0.0474 - output_ulica_accuracy: 0.6986 - output_ulica_loss: 1.0940 - val_loss: 0.7893 - val_output_dzielnica_accuracy: 0.9950 - val_output_dzielnica_loss: 0.0319 - val_output_ulica_accuracy: 0.7794 - val_output_ulica_loss: 1.5196 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 373ms/step - loss: 0.5354 - output_dzielnica_accuracy: 0.9885 - output_dzielnica_loss: 0.0341 - output_ulica_accuracy: 0.7255 - output_ulica_loss: 1.0024 - val_loss: 0.7676 - val_output_dzielnica_accuracy: 0.9975 - val_output_dzielnica_loss: 0.0354 - val_output_ulica_accuracy: 0.7912 - val_output_ulica_loss: 1.4685 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 371ms/step - loss: 0.4906 - output_dzielnica_accuracy: 0.9883 - output_dzielnica_loss: 0.0419 - output_ulica_accuracy: 0.7449 - output_ulica_loss: 0.8974 - val_loss: 0.7473 - val_output_dzielnica_accuracy: 0.9963 - val_output_dzielnica_loss: 0.0288 - val_output_ulica_accuracy: 0.8178 - val_output_ulica_loss: 1.4440 - learning_rate: 0.0010\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 3: BUDOWA I TRENING MODELU HIERARCHICZNEGO ===\n",
    "\n",
    "# --- 3.1: Definicja architektury ---\n",
    "# Wejścia\n",
    "input_text = Input(shape=(MAX_LEN,), name='text_input')\n",
    "input_numeric = Input(shape=(X_numeric.shape[1],), name='numeric_input')\n",
    "\n",
    "# Wspólny trzon\n",
    "text_embedding = Embedding(input_dim=MAX_WORDS, output_dim=128)(input_text)\n",
    "lstm_out = LSTM(128, dropout=0.3)(text_embedding)\n",
    "concatenated = Concatenate()([lstm_out, input_numeric])\n",
    "common_dense = Dense(128, activation='relu')(concatenated)\n",
    "common_dense = Dropout(0.5)(common_dense)\n",
    "\n",
    "# Gałąź wyjściowa dla DZIELNICY\n",
    "dzielnica_branch = Dense(64, activation='relu')(common_dense)\n",
    "dzielnica_output = Dense(num_classes_dzielnica, activation='softmax', name='output_dzielnica')(dzielnica_branch)\n",
    "\n",
    "# Gałąź wyjściowa dla ULICY\n",
    "ulica_branch = Dense(256, activation='relu')(common_dense)\n",
    "ulica_output = Dense(num_classes_ulica, activation='softmax', name='output_ulica')(ulica_branch)\n",
    "\n",
    "# --- 3.2: Kompilacja modelu ---\n",
    "model = Model(inputs=[input_text, input_numeric], outputs=[dzielnica_output, ulica_output])\n",
    "\n",
    "# Definiujemy osobne straty dla każdego wyjścia\n",
    "losses = {\n",
    "    \"output_dzielnica\": \"sparse_categorical_crossentropy\",\n",
    "    \"output_ulica\": \"sparse_categorical_crossentropy\",\n",
    "}\n",
    "\n",
    "# Definiujemy wagi dla każdej ze strat\n",
    "loss_weights = {\n",
    "    \"output_dzielnica\": 1.0,\n",
    "    \"output_ulica\": 0.5\n",
    "}\n",
    "\n",
    "# POPRAWKA: Definiujemy metryki dla każdego wyjścia osobno\n",
    "metrics = {\n",
    "    \"output_dzielnica\": \"accuracy\",\n",
    "    \"output_ulica\": \"accuracy\"\n",
    "}\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses,\n",
    "    loss_weights=loss_weights,\n",
    "    metrics=metrics  # Przekazujemy słownik metryk\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# --- 3.3: Trening ---\n",
    "X_train = [X_train_text, X_train_num]\n",
    "y_train = {'output_dzielnica': y_train_dzielnica, 'output_ulica': y_train_ulica}\n",
    "X_val = [X_val_text, X_val_num]\n",
    "y_val = {'output_dzielnica': y_val_dzielnica, 'output_ulica': y_val_ulica}\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_output_dzielnica_accuracy', \n",
    "        patience=5, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1,\n",
    "        mode='max'  # <-- DODAJ TĘ LINIĘ\n",
    "    ),\n",
    "    ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nRozpoczynam trening modelu hierarchicznego...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525a735d-3ee1-49c9-b051-4d743bc13d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wszystkie artefakty zostały zapisane w folderze: 'model_artifacts_final'\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 4: ZAPIS ARTEFAKTÓW DO PRODUKCJI ===\n",
    "artifacts_dir = 'model_artifacts_final'\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# 1. Zapis modelu\n",
    "model.save(os.path.join(artifacts_dir, 'final_hierarchical_model.keras'))\n",
    "\n",
    "# 2. Zapis Tokenizera\n",
    "with open(os.path.join(artifacts_dir, 'tokenizer.pkl'), 'wb') as f: pickle.dump(tokenizer, f)\n",
    "\n",
    "# 3. Zapis pipelinu numerycznego\n",
    "with open(os.path.join(artifacts_dir, 'numeric_pipeline.pkl'), 'wb') as f: pickle.dump(numeric_pipeline, f)\n",
    "\n",
    "# 4. Zapis koderów dla zmiennych celu\n",
    "with open(os.path.join(artifacts_dir, 'le_dzielnica.pkl'), 'wb') as f: pickle.dump(le_dzielnica, f)\n",
    "with open(os.path.join(artifacts_dir, 'le_ulica.pkl'), 'wb') as f: pickle.dump(le_ulica, f)\n",
    "\n",
    "print(f\"\\nWszystkie artefakty zostały zapisane w folderze: '{artifacts_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a2df07-2cb0-47a0-85ee-a78a2183713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rozpoczynam proces predykcji na pełnym zbiorze danych ---\n",
      "Wczytuję artefakty z folderu: 'model_artifacts_final'...\n",
      "Artefakty wczytane pomyślnie.\n",
      "\n",
      "Przygotowuję 235700 wierszy do predykcji...\n",
      "Znaleziono 179492 wierszy, na których można wykonać predykcję.\n",
      "\n",
      "Rozpoczynam predykcję modelem LSTM...\n",
      "\u001b[1m5610/5610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 64ms/step\n",
      "Predykcja zakończona.\n",
      "\n",
      "Przykładowe wyniki predykcji:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Area</th>\n",
       "      <th>Price</th>\n",
       "      <th>BuiltYear</th>\n",
       "      <th>predicted_dzielnica</th>\n",
       "      <th>predicted_ulica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mieszkanie, Mokotów</td>\n",
       "      <td>167.25</td>\n",
       "      <td>2893425.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Bielany</td>\n",
       "      <td>Kolektorska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dwupoziomowy apartament w doskonałej lokalizacji</td>\n",
       "      <td>93.36</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>Bielany</td>\n",
       "      <td>Kolektorska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bezpośrednio! mieszkanie - Wilanów</td>\n",
       "      <td>41.00</td>\n",
       "      <td>649000.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Praga-południe</td>\n",
       "      <td>Drewnicka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mieszkanie 3-pokoje, umeblowane, po remoncie</td>\n",
       "      <td>62.00</td>\n",
       "      <td>880000.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Mokotów</td>\n",
       "      <td>Sozopolska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PREMIUM !!! Apartament z Widokiem 22Piętro!Taras!</td>\n",
       "      <td>46.00</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Żoliborz</td>\n",
       "      <td>Kolektorska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mieszkanie Bródno, ul. Wysockiego</td>\n",
       "      <td>53.50</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>Żoliborz</td>\n",
       "      <td>Bieniewicka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Moja Północna II | mieszkanie B 3</td>\n",
       "      <td>41.05</td>\n",
       "      <td>496705.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Ursus</td>\n",
       "      <td>Quo vadis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mieszkanie Warszawa Śródmieście, ul. Jana Pawł...</td>\n",
       "      <td>64.00</td>\n",
       "      <td>879000.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>Żoliborz</td>\n",
       "      <td>Gwiaździsta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3 pokoje Mokotów Woronicza/Suwak</td>\n",
       "      <td>75.00</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Żoliborz</td>\n",
       "      <td>Bieniewicka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mieszkanie trzypokojowe na sprzedaż</td>\n",
       "      <td>100.00</td>\n",
       "      <td>799000.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Praga-południe</td>\n",
       "      <td>Podolska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mieszkanie, Warszawa, Wola, 65 m²</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>Wola</td>\n",
       "      <td>Gumińska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nowe mieszkanie Warszawa Bemowo, ul. Kruszyńska</td>\n",
       "      <td>112.05</td>\n",
       "      <td>1695000.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Praga-południe</td>\n",
       "      <td>Gruzińska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mieszkanie Wola, ul. Kruszyńska</td>\n",
       "      <td>112.00</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Bielany</td>\n",
       "      <td>Kolektorska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mieszkanie, 70,29 m², Warszawa</td>\n",
       "      <td>70.29</td>\n",
       "      <td>835000.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Żoliborz</td>\n",
       "      <td>Bieniewicka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mieszkanie Wola, ul. Kruszyńska</td>\n",
       "      <td>108.00</td>\n",
       "      <td>1695000.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Bielany</td>\n",
       "      <td>Kolektorska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mieszkanie trzypokojowe na sprzedaż</td>\n",
       "      <td>52.54</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>Praga-północ</td>\n",
       "      <td>Aleja tysiąclecia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nowa inwestycja! Do wprowadzenia! A.Jerozolimskie</td>\n",
       "      <td>46.00</td>\n",
       "      <td>658000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Ursus</td>\n",
       "      <td>Michała drzymały</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sprzedam piękny apartament w Wilanowie Królewskim</td>\n",
       "      <td>76.88</td>\n",
       "      <td>1345000.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Praga-południe</td>\n",
       "      <td>Gruzińska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stylowy Apartament na Mokotowskiej</td>\n",
       "      <td>94.00</td>\n",
       "      <td>2541000.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>Bielany</td>\n",
       "      <td>Kolektorska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sprzedam apartament w Mennica Residence (53,7m2)</td>\n",
       "      <td>53.07</td>\n",
       "      <td>1379820.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Ochota</td>\n",
       "      <td>Ludwika krzywickiego</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title    Area      Price  \\\n",
       "0                                 Mieszkanie, Mokotów  167.25  2893425.0   \n",
       "1    Dwupoziomowy apartament w doskonałej lokalizacji   93.36  3500000.0   \n",
       "2                  Bezpośrednio! mieszkanie - Wilanów   41.00   649000.0   \n",
       "4        Mieszkanie 3-pokoje, umeblowane, po remoncie   62.00   880000.0   \n",
       "5   PREMIUM !!! Apartament z Widokiem 22Piętro!Taras!   46.00   850000.0   \n",
       "6                   Mieszkanie Bródno, ul. Wysockiego   53.50   650000.0   \n",
       "7                   Moja Północna II | mieszkanie B 3   41.05   496705.0   \n",
       "12  Mieszkanie Warszawa Śródmieście, ul. Jana Pawł...   64.00   879000.0   \n",
       "14                   3 pokoje Mokotów Woronicza/Suwak   75.00  1200000.0   \n",
       "15               Mieszkanie trzypokojowe na sprzedaż   100.00   799000.0   \n",
       "16                  Mieszkanie, Warszawa, Wola, 65 m²   65.00  1500000.0   \n",
       "17   Nowe mieszkanie Warszawa Bemowo, ul. Kruszyńska   112.05  1695000.0   \n",
       "18                    Mieszkanie Wola, ul. Kruszyńska  112.00  1575000.0   \n",
       "19                     Mieszkanie, 70,29 m², Warszawa   70.29   835000.0   \n",
       "20                    Mieszkanie Wola, ul. Kruszyńska  108.00  1695000.0   \n",
       "21               Mieszkanie trzypokojowe na sprzedaż    52.54   510000.0   \n",
       "22  Nowa inwestycja! Do wprowadzenia! A.Jerozolimskie   46.00   658000.0   \n",
       "24  Sprzedam piękny apartament w Wilanowie Królewskim   76.88  1345000.0   \n",
       "25                 Stylowy Apartament na Mokotowskiej   94.00  2541000.0   \n",
       "26   Sprzedam apartament w Mennica Residence (53,7m2)   53.07  1379820.0   \n",
       "\n",
       "    BuiltYear predicted_dzielnica       predicted_ulica  \n",
       "0      2022.0             Bielany           Kolektorska  \n",
       "1      1966.0             Bielany           Kolektorska  \n",
       "2      2017.0      Praga-południe             Drewnicka  \n",
       "4      1960.0             Mokotów            Sozopolska  \n",
       "5      2021.0            Żoliborz           Kolektorska  \n",
       "6      1974.0            Żoliborz           Bieniewicka  \n",
       "7      2023.0               Ursus             Quo vadis  \n",
       "12     1953.0            Żoliborz           Gwiaździsta  \n",
       "14     2020.0            Żoliborz           Bieniewicka  \n",
       "15     1996.0      Praga-południe              Podolska  \n",
       "16     1936.0                Wola              Gumińska  \n",
       "17     2022.0      Praga-południe             Gruzińska  \n",
       "18     2022.0             Bielany           Kolektorska  \n",
       "19     2008.0            Żoliborz           Bieniewicka  \n",
       "20     2022.0             Bielany           Kolektorska  \n",
       "21     1933.0        Praga-północ     Aleja tysiąclecia  \n",
       "22     2019.0               Ursus      Michała drzymały  \n",
       "24     2011.0      Praga-południe             Gruzińska  \n",
       "25     1890.0             Bielany           Kolektorska  \n",
       "26     2020.0              Ochota  Ludwika krzywickiego  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === SEKCJA 5: PREdykcja na pełnym zbiorze danych i interpretacja wyników ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"--- Rozpoczynam proces predykcji na pełnym zbiorze danych ---\")\n",
    "\n",
    "# --- 5.1: Wczytanie zapisanych artefaktów ---\n",
    "artifacts_dir = 'model_artifacts_final'\n",
    "try:\n",
    "    print(f\"Wczytuję artefakty z folderu: '{artifacts_dir}'...\")\n",
    "    model = load_model(os.path.join(artifacts_dir, 'final_hierarchical_model.keras'))\n",
    "    with open(os.path.join(artifacts_dir, 'tokenizer.pkl'), 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    with open(os.path.join(artifacts_dir, 'numeric_pipeline.pkl'), 'rb') as f:\n",
    "        numeric_pipeline = pickle.load(f)\n",
    "    with open(os.path.join(artifacts_dir, 'le_dzielnica.pkl'), 'rb') as f:\n",
    "        le_dzielnica = pickle.load(f)\n",
    "    with open(os.path.join(artifacts_dir, 'le_ulica.pkl'), 'rb') as f:\n",
    "        le_ulica = pickle.load(f)\n",
    "    print(\"Artefakty wczytane pomyślnie.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"BŁĄD: Nie znaleziono pliku z artefaktem: {e.filename}. Upewnij się, że model został poprawnie wytrenowany i zapisany.\")\n",
    "    raise\n",
    "\n",
    "# --- 5.2: Wczytanie i przygotowanie pełnego zbioru danych ---\n",
    "# Używamy df_main_raw, który powinien być w pamięci z komórki #1, aby nie wczytywać pliku ponownie.\n",
    "print(f\"\\nPrzygotowuję {len(df_main_raw)} wierszy do predykcji...\")\n",
    "df_to_predict = df_main_raw.copy()\n",
    "\n",
    "# KROK 1: Użyj IDENTYCZNEGO mapowania kolumn jak w treningu\n",
    "main_cols_map = {\n",
    "    0: 'SaleId',\n",
    "    3: 'Title',\n",
    "    4: 'Description',\n",
    "    5: 'Area',\n",
    "    6: 'Price',\n",
    "    12: 'BuiltYear',     # <-- POPRAWIONY INDEKS\n",
    "    17: 'NumberOfRooms',\n",
    "    35: 'Floor',\n",
    "    36: 'Floors'\n",
    "}\n",
    "df_to_predict.rename(columns=main_cols_map, inplace=True)\n",
    "\n",
    "# KROK 2: Wykonaj IDENTYCZNE przetwarzanie cech jak w treningu\n",
    "text_features = ['Title', 'Description']\n",
    "numeric_features = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'BuiltYear']\n",
    "\n",
    "for col in text_features:\n",
    "    df_to_predict[col] = df_to_predict[col].fillna('')\n",
    "for col in numeric_features:\n",
    "    df_to_predict[col] = pd.to_numeric(df_to_predict[col], errors='coerce')\n",
    "\n",
    "# KROK 3: Odfiltruj wiersze, które nie mają kluczowych danych numerycznych\n",
    "df_valid_for_pred = df_to_predict.dropna(subset=numeric_features).copy()\n",
    "print(f\"Znaleziono {len(df_valid_for_pred)} wierszy, na których można wykonać predykcję.\")\n",
    "\n",
    "# KROK 4: Stwórz dodatkowe cechy, tak jak w treningu\n",
    "# A. Stwórz cechę 'Price_per_sqm'\n",
    "df_valid_for_pred['Price_per_sqm'] = df_valid_for_pred['Price'] / df_valid_for_pred['Area']\n",
    "df_valid_for_pred['Price_per_sqm'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# B. Wzbogać i wyczyść opis. UWAGA: Tutaj nie dodajemy Dzielnicy i Ulicy, bo ich nie znamy!\n",
    "df_valid_for_pred['description_enriched'] = df_valid_for_pred['Title'] + \" \" + df_valid_for_pred['Description']\n",
    "def clean_text(text): return re.sub(r'[^a-ząęółśżźćń ]', '', str(text).lower())\n",
    "df_valid_for_pred['description_clean'] = df_valid_for_pred['description_enriched'].apply(clean_text)\n",
    "\n",
    "# --- 5.3: Transformacja danych przy użyciu wczytanych artefaktów ---\n",
    "MAX_LEN = 250 # Musi być takie samo jak podczas treningu\n",
    "\n",
    "# A. Przetwarzanie danych tekstowych\n",
    "X_text_pred = pad_sequences(tokenizer.texts_to_sequences(df_valid_for_pred['description_clean']), maxlen=MAX_LEN)\n",
    "\n",
    "# B. Przetwarzanie danych numerycznych\n",
    "# Lista kolumn MUSI być identyczna jak w treningu\n",
    "numeric_features_cols_pipeline = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'BuiltYear', 'Price_per_sqm']\n",
    "X_numeric_pred = numeric_pipeline.transform(df_valid_for_pred[numeric_features_cols_pipeline])\n",
    "\n",
    "# --- 5.4: Wykonanie predykcji ---\n",
    "print(\"\\nRozpoczynam predykcję modelem LSTM...\")\n",
    "predictions = model.predict([X_text_pred, X_numeric_pred])\n",
    "pred_dzielnica_probs = predictions[0]\n",
    "pred_ulica_probs = predictions[1]\n",
    "print(\"Predykcja zakończona.\")\n",
    "\n",
    "# === SEKCJA 5.5: INTELIGENTNA INTERPRETACJA WYNIKÓW (z korektą) ===\n",
    "\n",
    "# Krok 1: Przewidujemy dzielnicę (tak jak wcześniej)\n",
    "pred_dzielnica_indices = np.argmax(pred_dzielnica_probs, axis=1)\n",
    "predicted_dzielnica_names = le_dzielnica.inverse_transform(pred_dzielnica_indices)\n",
    "df_valid_for_pred['predicted_dzielnica'] = predicted_dzielnica_names\n",
    "\n",
    "# Krok 2: Przygotowujemy dane do inteligentnej predykcji ulicy\n",
    "# Mapowanie: Nazwa dzielnicy -> lista poprawnych nazw ulic\n",
    "dzielnica_to_ulice_map = df_slownik.groupby('Dzielnica_Name')['Ulica_Name'].apply(list).to_dict()\n",
    "# Mapowanie: Nazwa ulicy -> jej indeks w modelu\n",
    "ulica_name_to_idx_map = {name: i for i, name in enumerate(le_ulica.classes_)}\n",
    "\n",
    "corrected_ulica_indices = []\n",
    "# Iterujemy przez każdą predykcję\n",
    "for i in range(len(predicted_dzielnica_names)):\n",
    "    # Bierzemy przewidzianą dzielnicę dla i-tego wiersza\n",
    "    dzielnica = predicted_dzielnica_names[i]\n",
    "    \n",
    "    # Pobieramy listę poprawnych ulic dla tej dzielnicy\n",
    "    valid_ulica_names = dzielnica_to_ulice_map.get(dzielnica, [])\n",
    "    \n",
    "    # Konwertujemy nazwy ulic na ich indeksy, których używa model\n",
    "    valid_ulica_indices = [ulica_name_to_idx_map[name] for name in valid_ulica_names if name in ulica_name_to_idx_map]\n",
    "    \n",
    "    if not valid_ulica_indices:\n",
    "        # Jeśli z jakiegoś powodu nie ma ulic dla dzielnicy, wybierz po prostu najlepszą globalnie\n",
    "        corrected_ulica_indices.append(np.argmax(pred_ulica_probs[i]))\n",
    "        continue\n",
    "\n",
    "    # Bierzemy pełny wektor prawdopodobieństw dla ulic dla i-tego wiersza\n",
    "    all_ulica_probs = pred_ulica_probs[i]\n",
    "    \n",
    "    # Wybieramy prawdopodobieństwa tylko dla poprawnych ulic\n",
    "    valid_probs = all_ulica_probs[valid_ulica_indices]\n",
    "    \n",
    "    # Znajdujemy indeks NAJLEPSZEJ ulicy WŚRÓD poprawnych ulic\n",
    "    best_local_idx = np.argmax(valid_probs)\n",
    "    \n",
    "    # Tłumaczymy ten lokalny indeks z powrotem na globalny indeks ulicy\n",
    "    final_ulica_idx = valid_ulica_indices[best_local_idx]\n",
    "    \n",
    "    corrected_ulica_indices.append(final_ulica_idx)\n",
    "\n",
    "# Krok 3: Użyj skorygowanych indeksów do finalnej predykcji\n",
    "df_valid_for_pred['predicted_ulica'] = le_ulica.inverse_transform(corrected_ulica_indices)\n",
    "\n",
    "# --- 5.6: Wyświetlenie wyników ---\n",
    "print(\"\\nPrzykładowe wyniki predykcji:\")\n",
    "display(df_valid_for_pred[[\n",
    "    'Title',\n",
    "    'Area',\n",
    "    'Price',\n",
    "    'BuiltYear',\n",
    "    'predicted_dzielnica',\n",
    "    'predicted_ulica'\n",
    "]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1d3d3-c4d7-4e5f-a46c-2f3a5b57baf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e40df38-3984-4b1f-b3ad-93ceccdf8c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
