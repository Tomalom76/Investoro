{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5a728e-447f-427c-864d-2e4a075174b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow ustawiony. Eksperyment: 'Warsaw_Street_Prediction_v3_FINAL'\n",
      "\n",
      "Wczytywanie danych...\n",
      "Wszystkie pliki wczytane pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 1: IMPORT I KONFIGURACJA ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pycaret.classification import setup, compare_models, tune_model, finalize_model, save_model, pull\n",
    "from IPython.display import display\n",
    "\n",
    "# Konfiguracja MLflow\n",
    "MLFLOW_EXPERIMENT_NAME = 'Warsaw_Street_Prediction_v3_FINAL'\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "print(f\"MLflow ustawiony. Eksperyment: '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "\n",
    "# Wczytanie danych\n",
    "print(\"\\nWczytywanie danych...\")\n",
    "df_main = pd.read_csv('data.csv', sep=',')\n",
    "df_simc = pd.read_csv('Simc.csv', sep=',')\n",
    "df_terc = pd.read_csv('Terc.csv', sep=',')\n",
    "df_ulic = pd.read_csv('Ulic.csv', sep=',')\n",
    "print(\"Wszystkie pliki wczytane pomyślnie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2a09fb-ea98-4a18-af1a-9bddb041d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Połączono słowniki. Rozmiar finalnej tabeli geograficznej: (293077, 12)\n",
      "\n",
      "Przykładowe dane z połączonej tabeli geograficznej:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYM_UL</th>\n",
       "      <th>NAZWA_ULICY</th>\n",
       "      <th>NAZWA_MIEJSCOWOSCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25133</td>\n",
       "      <td>Wyzwolenia</td>\n",
       "      <td>Miedźno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20298</td>\n",
       "      <td>Słowicza</td>\n",
       "      <td>Wola aleksandra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04212</td>\n",
       "      <td>Droga dzików</td>\n",
       "      <td>Jesówka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19830</td>\n",
       "      <td>Sienkiewicza</td>\n",
       "      <td>Gwoździany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60067</td>\n",
       "      <td>4 czerwca 1989 r.</td>\n",
       "      <td>Chrzanów</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SYM_UL        NAZWA_ULICY NAZWA_MIEJSCOWOSCI\n",
       "0  25133         Wyzwolenia            Miedźno\n",
       "1  20298           Słowicza    Wola aleksandra\n",
       "2  04212       Droga dzików            Jesówka\n",
       "3  19830       Sienkiewicza         Gwoździany\n",
       "4  60067  4 czerwca 1989 r.           Chrzanów"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === SEKCJA 2: TWORZENIE KOMPLETNEJ TABELI GEOGRAFICZNEJ ===\n",
    "\n",
    "# --- Krok 2a: Czyszczenie i przygotowanie tabel TERYT ---\n",
    "# Upewniamy się, że kluczowe kolumny są w poprawnym formacie (stringi o stałej długości)\n",
    "df_terc['WOJ'] = df_terc['VoivodeshipNumber'].astype(str).str.zfill(2)\n",
    "df_terc['POW'] = df_terc['CountyNumber'].astype(str).str.zfill(2)\n",
    "df_terc['GMI'] = df_terc['CommunityNumber'].astype(str).str.zfill(2)\n",
    "df_terc['RODZ'] = df_terc['KindNumber'].astype(str)\n",
    "df_terc['TERYT_GMI'] = df_terc['WOJ'] + df_terc['POW'] + df_terc['GMI'] + df_terc['RODZ']\n",
    "\n",
    "df_simc['WOJ'] = df_simc['VoivodeshipNumber'].astype(str).str.zfill(2)\n",
    "df_simc['POW'] = df_simc['CountyNumber'].astype(str).str.zfill(2)\n",
    "df_simc['GMI'] = df_simc['CommunityNumber'].astype(str).str.zfill(2)\n",
    "df_simc['RODZ_GMI'] = df_simc['KindNumber'].astype(str)\n",
    "df_simc['TERYT_MIASTA'] = df_simc['WOJ'] + df_simc['POW'] + df_simc['GMI'] + df_simc['RODZ_GMI']\n",
    "\n",
    "df_ulic['SYM_UL'] = df_ulic['SymUl'].astype(str).str.zfill(5)\n",
    "df_ulic['SYM'] = df_ulic['Sym'].astype(str).str.zfill(7)\n",
    "df_ulic.rename(columns={'Name': 'NAZWA_ULICY', 'Feature': 'CECHA_ULICY'}, inplace=True)\n",
    "\n",
    "# --- Krok 2b: Łączenie tabel pomocniczych ---\n",
    "# Łączymy ulice z miejscowościami po symbolu miejscowości 'SYM'\n",
    "df_geo = pd.merge(df_ulic, df_simc[['Sym', 'Name']], on='Sym', how='left')\n",
    "df_geo.rename(columns={'Name': 'NAZWA_MIEJSCOWOSCI'}, inplace=True)\n",
    "\n",
    "print(f\"Połączono słowniki. Rozmiar finalnej tabeli geograficznej: {df_geo.shape}\")\n",
    "print(\"\\nPrzykładowe dane z połączonej tabeli geograficznej:\")\n",
    "display(df_geo[['SYM_UL', 'NAZWA_ULICY', 'NAZWA_MIEJSCOWOSCI']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ba72e6-0fb9-4669-94fe-e524894eb0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wierszy z przypisaną ulicą ze słownika: 10180035\n",
      "\n",
      "Po wzbogaceniu i czyszczeniu -> Pozostało wierszy: 8749444, Unikalnych ulic: 4120\n",
      "Finalny kształt zbioru gotowego do modelowania: (8749444, 306)\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 3: WZBOGACANIE I CZYSZCZENIE DANYCH GŁÓWNYCH ===\n",
    "\n",
    "# --- Krok 3a: Wzbogacanie danych głównych o nazwy ulic ---\n",
    "df_enriched = df_main.copy()\n",
    "# Upewniamy się, że klucz 'StreetNumber' jest w tym samym formacie co 'SYM_UL'\n",
    "df_enriched['SYM_UL_str'] = df_enriched['StreetNumber'].astype('Int64').astype(str).str.zfill(5)\n",
    "# Łączymy po kluczu\n",
    "df_enriched = pd.merge(df_enriched, df_geo[['SYM_UL', 'NAZWA_ULICY', 'NAZWA_MIEJSCOWOSCI']],\n",
    "                       left_on='SYM_UL_str', right_on='SYM_UL', how='left')\n",
    "\n",
    "print(f\"Liczba wierszy z przypisaną ulicą ze słownika: {df_enriched['NAZWA_ULICY'].notna().sum()}\")\n",
    "\n",
    "# --- Krok 3b: Stworzenie finalnej kolumny celu 'Ulica_clean' ---\n",
    "def get_final_street(row):\n",
    "    # Priorytet ma ulica ze słownika TERYT\n",
    "    if pd.notna(row['NAZWA_ULICY']):\n",
    "        return str(row['NAZWA_ULICY']).lower()\n",
    "    \n",
    "    # Jeśli nie, próbujemy parsować 'Location'\n",
    "    location = row['Location']\n",
    "    if isinstance(location, str) and len(location.split(',')) >= 4:\n",
    "        street = location.split(',')[3].strip()\n",
    "        street = re.sub(r'^(ul\\.|al\\.|pl\\.)\\s*', '', street, flags=re.IGNORECASE).lower()\n",
    "        if len(street) > 2:\n",
    "            return street\n",
    "    return np.nan\n",
    "\n",
    "df_enriched['Ulica_clean'] = df_enriched.apply(get_final_street, axis=1)\n",
    "\n",
    "# --- Krok 3c: Czyszczenie ---\n",
    "df_enriched.dropna(subset=['Ulica_clean', 'Area', 'Price', 'Description'], inplace=True)\n",
    "df_enriched['BuiltYear'] = pd.to_datetime(df_enriched['BuiltYear'], format='%Y', errors='coerce')\n",
    "q_low, q_hi = df_enriched[\"Price\"].quantile(0.01), df_enriched[\"Price\"].quantile(0.99)\n",
    "df_enriched = df_enriched[(df_enriched[\"Price\"] < q_hi) & (df_enriched[\"Price\"] > q_low)]\n",
    "\n",
    "print(f\"\\nPo wzbogaceniu i czyszczeniu -> Pozostało wierszy: {len(df_enriched)}, Unikalnych ulic: {df_enriched['Ulica_clean'].nunique()}\")\n",
    "\n",
    "# --- Krok 3d: TF-IDF ---\n",
    "vectorizer = TfidfVectorizer(max_features=250, ngram_range=(1, 3), min_df=10)\n",
    "df_enriched.reset_index(drop=True, inplace=True)\n",
    "tfidf_features = vectorizer.fit_transform(df_enriched['Description'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=['des_tfidf_' + name for name in feature_names])\n",
    "df_final = pd.concat([df_enriched, tfidf_df], axis=1)\n",
    "\n",
    "print(f\"Finalny kształt zbioru gotowego do modelowania: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97147882-8d62-4860-b0af-c021846b2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po odfiltrowaniu rzadkich ulic -> Pozostało wierszy: 8741834, Unikalnych ulic: 2501\n",
      "\n",
      "Podział danych -> Treningowe: (7867651, 306), Testowe: (874183, 306)\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 4: PRZYGOTOWANIE DO MODELOWANIA ===\n",
    "MIN_SAMPLES_PER_STREET = 15\n",
    "street_counts = df_final['Ulica_clean'].value_counts()\n",
    "streets_to_remove = street_counts[street_counts < MIN_SAMPLES_PER_STREET].index\n",
    "df_model_ready = df_final[~df_final['Ulica_clean'].isin(streets_to_remove)].copy()\n",
    "print(f\"Po odfiltrowaniu rzadkich ulic -> Pozostało wierszy: {len(df_model_ready)}, Unikalnych ulic: {df_model_ready['Ulica_clean'].nunique()}\")\n",
    "\n",
    "data_train = df_model_ready.sample(frac=0.9, random_state=1122)\n",
    "data_test = df_model_ready.drop(data_train.index)\n",
    "fold_groups = data_train['Ulica_clean']\n",
    "print(f\"\\nPodział danych -> Treningowe: {data_train.shape}, Testowe: {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2717cc49-a48f-46fe-844c-ec8e59f733e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/18 22:28:43 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8               Ignore features   \n",
      "9              Numeric features   \n",
      "10                Date features   \n",
      "11         Categorical features   \n",
      "12     Rows with missing values   \n",
      "13                   Preprocess   \n",
      "14              Imputation type   \n",
      "15           Numeric imputation   \n",
      "16       Categorical imputation   \n",
      "17     Maximum one-hot encoding   \n",
      "18              Encoding method   \n",
      "19               Fold Generator   \n",
      "20                  Fold Number   \n",
      "21                     CPU Jobs   \n",
      "22                      Use GPU   \n",
      "23               Log Experiment   \n",
      "24              Experiment Name   \n",
      "25                          USI   \n",
      "\n",
      "                                                Value  \n",
      "0                                                1122  \n",
      "1                                         Ulica_clean  \n",
      "2                                          Multiclass  \n",
      "3   1 maja: 0, 1 praskiego pułku wp: 1, 1 sierpnia...  \n",
      "4                                      (8741834, 306)  \n",
      "5                                      (8741834, 294)  \n",
      "6                                      (7867651, 294)  \n",
      "7                                       (874183, 294)  \n",
      "8                                                  14  \n",
      "9                                                 279  \n",
      "10                                                  1  \n",
      "11                                                 11  \n",
      "12                                             100.0%  \n",
      "13                                               True  \n",
      "14                                             simple  \n",
      "15                                               mean  \n",
      "16                                               mode  \n",
      "17                                                 25  \n",
      "18                                               None  \n",
      "19                                         GroupKFold  \n",
      "20                                                 10  \n",
      "21                                                  4  \n",
      "22                                              False  \n",
      "23                                              False  \n",
      "24                                   clf-default-name  \n",
      "25                                               2993  \n",
      "\n",
      "Rozpoczynam porównywanie modeli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    }
   ],
   "source": [
    "# === SEKCJA 5: SETUP I TRENING ===\n",
    "if mlflow.active_run(): mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Warsaw_Street_Prediction_v3\") as run:\n",
    "    # Użyjemy zautomatyzowanego wyboru cech przez PyCaret, ignorując tylko to, co konieczne\n",
    "    s = setup(\n",
    "        data=data_train, test_data=data_test, target='Ulica_clean',\n",
    "        session_id=1122, n_jobs=4, fold_strategy='groupkfold', fold_groups=fold_groups,\n",
    "        ignore_features=['SaleId', 'OriginalId', 'Location', 'Description', 'Title', 'Link', 'Phone', 'MainImage', 'OtherImages', 'EncryptedId', 'SYM_UL_str', 'SYM_UL', 'NAZWA_ULICY', 'NAZWA_MIEJSCOWOSCI'],\n",
    "        log_experiment=False, html=False, verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nRozpoczynam porównywanie modeli...\")\n",
    "    best_model = compare_models(include=['lightgbm', 'rf', 'et'], sort='F1') # Usunięto xgboost na razie, aby przyspieszyć test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91df5f4-34fb-4152-8063-969cdad9d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęto run w MLflow: d136b02823334da1bc9c15c55c8ff6de\n",
      "Rozpoczynam porównywanie modeli (ze stabilizacją i modelem dummy)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porównanie modeli zakończone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UWAGA: Żaden z testowanych modeli nie zakończył treningu pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 6: TRENING I LOGOWANIE DO MLFLOW (ULEPSZONE) ===\n",
    "\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Warsaw_Street_Prediction_Run_v2\") as run:\n",
    "    print(f\"Rozpoczęto run w MLflow: {run.info.run_id}\")\n",
    "    print(\"Rozpoczynam porównywanie modeli (ze stabilizacją i modelem dummy)...\")\n",
    "    \n",
    "    # Dodajemy 'dummy' do listy, aby mieć punkt odniesienia\n",
    "    models_to_try = ['lightgbm', 'xgboost', 'rf', 'dummy']\n",
    "    \n",
    "    best_model = compare_models(include=models_to_try, sort='F1')\n",
    "    \n",
    "    print(\"\\nPorównanie modeli zakończone.\")\n",
    "    \n",
    "    all_models_metrics = pull()\n",
    "    display(all_models_metrics)\n",
    "    \n",
    "    if not all_models_metrics.empty:\n",
    "        all_models_metrics.to_csv(\"compare_models_results_v2.csv\")\n",
    "        mlflow.log_artifact(\"compare_models_results_v2.csv\")\n",
    "        print(f\"\\nNajlepszy zidentyfikowany model: {best_model}\")\n",
    "    else:\n",
    "        print(\"\\nUWAGA: Żaden z testowanych modeli nie zakończył treningu pomyślnie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4727b-732c-4a41-8314-cf58f2e56c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
