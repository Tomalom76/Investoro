{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172fa98d-b25c-4b46-b1aa-9e684d5b2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ai\\AppData\\Local\\Temp\\ipykernel_17092\\3376309559.py:109: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  years = pd.to_datetime(full['BuiltYear'], errors='coerce').dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== Balans klas przed treningiem ===\n",
      "                   count  percent\n",
      "BuildingCondition                \n",
      "AFTER_RENOVATION   22000    25.14\n",
      "DEVELOPER_STATE    22000    25.14\n",
      "FOR_RENOVATION     21513    24.58\n",
      "GOOD               22000    25.14\n",
      "\\nClass weights: {0: 0.9944602272727273, 1: 0.9944602272727273, 2: 1.0169959325973272, 3: 0.9944602272727273}\n"
     ]
    }
   ],
   "source": [
    "# --- KONFIGURACJA I WCIĄGANIE NOWYCH BAZ ---\n",
    "\n",
    "import os, csv, io, re, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 4 źródła (każdy plik = jedna etykieta docelowa)\n",
    "FILES = {\n",
    "    'sf_after_renovation.csv': 'AFTER_RENOVATION',\n",
    "    'sf_developer_state.csv' : 'DEVELOPER_STATE',\n",
    "    'sf_for_renovation.csv' : 'FOR_RENOVATION',\n",
    "    'sf_good.csv' : 'GOOD',\n",
    "}\n",
    "\n",
    "# Wymagane przez model pola (zgodnie z notebookiem trenowania)\n",
    "REQUIRED_TEXT = ['Description']\n",
    "REQUIRED_NUM  = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors']\n",
    "REQUIRED_CAT  = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "REQUIRED_DT   = ['BuiltYear']  # źródło kolumny 'year'\n",
    "REQUIRED_ALL  = REQUIRED_TEXT + REQUIRED_NUM + REQUIRED_CAT + REQUIRED_DT\n",
    "\n",
    "# UWAGA: pliki źródłowe mają stałą kolejność kolumn w rekordach CSV.\n",
    "# Na podstawie diagnostyki i próbek w notatniku mapujemy pozycje -> nazwy:\n",
    "#  idx:  4=Description, 5=Area, 6=Price, 11=NumberOfRooms, 12=BuiltYear,\n",
    "#       14=BuildingType, 16=OfferFrom, 17=Floor, 18=Floors, 19=TypeOfMarket, 15=etykieta źródłowa\n",
    "IDX_MAP = {\n",
    "    'Description':   4,\n",
    "    'Area':          5,\n",
    "    'Price':         6,\n",
    "    'NumberOfRooms': 11,\n",
    "    'BuiltYear':     12,\n",
    "    'BuildingType':  14,\n",
    "    'OfferFrom':     16,\n",
    "    'Floor':         17,\n",
    "    'Floors':        18,\n",
    "    'TypeOfMarket':  19,\n",
    "}\n",
    "IDX_LABEL = 15  # zawiera nazwę stanu w rekordach; dla pewności nadpisujemy etykietę nazwą pliku\n",
    "\n",
    "# Parser wymuszający prawidłowe dzielenie po przecinku i cudzysłowie, z escape'ami\n",
    "def robust_read_records(path, encoding_candidates=('utf-8-sig','utf-8','cp1250','latin1')):\n",
    "    last_err = None\n",
    "    for enc in encoding_candidates:\n",
    "        try:\n",
    "            rows = []\n",
    "            with open(path, 'r', encoding=enc, errors='replace', newline='') as f:\n",
    "                reader = csv.reader(f, delimiter=',', quotechar='\"', escapechar='\\\\')\n",
    "                for row in reader:\n",
    "                    # pomijamy puste/krótkie wiersze\n",
    "                    if not row or (len(row) == 1 and not row.strip()):\n",
    "                        continue\n",
    "                    rows.append(row)\n",
    "            if not rows:\n",
    "                continue\n",
    "            # Heurystyka: zbiór powinien mieć dziesiątki pól; jeśli wszystko skleiło się do 1 kolumny, to zły enc\n",
    "            median_len = int(np.median([len(r) for r in rows]))\n",
    "            if median_len < 10:\n",
    "                continue\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err:\n",
    "        raise last_err\n",
    "    raise RuntimeError(f'Unable to parse CSV: {path}')\n",
    "\n",
    "def extract_required_df(rows, force_label):\n",
    "    # Przekształć listę rekordów => DataFrame z wybranymi kolumnami po indeksach\n",
    "    sel = {}\n",
    "    ncols_needed = max(list(IDX_MAP.values()) + [IDX_LABEL]) + 1\n",
    "    for name, idx in IDX_MAP.items():\n",
    "        sel[name] = [ (r[idx] if len(r) > idx else None) for r in rows ]\n",
    "    # Etykieta (nadpisujemy nazwą pliku, aby uniezależnić się od zawartości)\n",
    "    labels = [ force_label for _ in rows ]\n",
    "    out = pd.DataFrame(sel)\n",
    "    out['BuildingCondition'] = labels\n",
    "    return out\n",
    "\n",
    "frames = []\n",
    "for path, label in FILES.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'Brak pliku: {path}')\n",
    "    rows = robust_read_records(path)\n",
    "    df_part = extract_required_df(rows, force_label=label)\n",
    "    frames.append(df_part)\n",
    "\n",
    "full = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# --- CZYSZCZENIE, TYPY, CECHY WTÓRNE ---\n",
    "\n",
    "# Tekst\n",
    "full['Description'] = full['Description'].fillna('').astype(str)\n",
    "\n",
    "# Numeryczne\n",
    "for col in ['Area','Price','NumberOfRooms','Floor','Floors']:\n",
    "    full[col] = pd.to_numeric(full[col], errors='coerce')\n",
    "\n",
    "# Rok budowy -> year (liczba całkowita); uwzględniamy formaty typu '2025' lub daty\n",
    "years = pd.to_datetime(full['BuiltYear'], errors='coerce').dt.year\n",
    "# Jeżeli wszystko NaN, spróbuj bezpośrednio rzutować na int\n",
    "if years.isna().all():\n",
    "    years = pd.to_numeric(full['BuiltYear'], errors='coerce')\n",
    "full['year'] = years\n",
    "# Uzupełnij medianą\n",
    "full['year'] = full['year'].fillna(full['year'].median())\n",
    "\n",
    "# Kategoryczne\n",
    "for col in ['BuildingType','OfferFrom','TypeOfMarket']:\n",
    "    full[col] = full[col].fillna('unknown').astype(str).str.strip().str.lower()\n",
    "\n",
    "# Normalizacja TypeOfMarket na 'pierwotny' / 'wtórny' / inne\n",
    "def norm_market(v):\n",
    "    v = (v or '').lower()\n",
    "    if 'pierwot' in v:\n",
    "        return 'pierwotny'\n",
    "    if 'wtór' in v or 'wtorn' in v:\n",
    "        return 'wtórny'\n",
    "    return v if v else 'unknown'\n",
    "full['TypeOfMarket'] = full['TypeOfMarket'].apply(norm_market)\n",
    "\n",
    "# Usunięcie oczywistych anomalii (opcjonalnie)\n",
    "# full = full[full['Area'] > 0]\n",
    "# full = full[full['Price'] > 0]\n",
    "\n",
    "# --- BALANS KLAS (PRZED TRENINGIEM) ---\n",
    "\n",
    "counts = full['BuildingCondition'].value_counts(dropna=False)\n",
    "perc   = (counts / len(full) * 100).round(2)\n",
    "balance = pd.DataFrame({'count': counts, 'percent': perc}).sort_index()\n",
    "print('\\\\n=== Balans klas przed treningiem ===')\n",
    "print(balance)\n",
    "\n",
    "# --- PODZIAŁ I PRZYGOTOWANIE WEJŚĆ ---\n",
    "\n",
    "# Mapa etykiet -> indeksy\n",
    "label_names = ['AFTER_RENOVATION','DEVELOPER_STATE','FOR_RENOVATION','GOOD']\n",
    "label_to_idx = {name: i for i, name in enumerate(label_names)}\n",
    "y_idx = full['BuildingCondition'].map(label_to_idx).astype(int).values\n",
    "y = to_categorical(y_idx, num_classes=len(label_names))\n",
    "\n",
    "# Tekst\n",
    "max_words, max_len = 10000, 200\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"\")\n",
    "tokenizer.fit_on_texts(full['Description'].astype(str))\n",
    "X_text = pad_sequences(tokenizer.texts_to_sequences(full['Description'].astype(str)), maxlen=max_len)\n",
    "\n",
    "# Tabelaryczne\n",
    "numeric_features = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'year']\n",
    "categorical_features = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_tabular = preprocessor.fit_transform(full[numeric_features + categorical_features])\n",
    "\n",
    "# Train/test split ze stratą po klasie\n",
    "X_text_train, X_text_test, X_tab_train, X_tab_test, y_train, y_test, y_idx_train, y_idx_test = train_test_split(\n",
    "    X_text, X_tabular, y, y_idx, test_size=0.2, random_state=42, stratify=y_idx\n",
    ")\n",
    "\n",
    "# --- WAŻENIE KLAS (opcjonalnie, przy dużej nierównowadze) ---\n",
    "classes = np.unique(y_idx_train)\n",
    "cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_idx_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "print('\\\\nClass weights:', class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e73bc9-0c3d-4c0f-81c6-618613f68d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tabular_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8220</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,072</span> │ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m1,280,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m49,408\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tabular_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8220\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │         \u001b[38;5;34m263,072\u001b[0m │ tabular_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m6,208\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │             \u001b[38;5;34m260\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,598,948</span> (6.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,598,948\u001b[0m (6.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,598,948</span> (6.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,598,948\u001b[0m (6.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nRozpoczynam trening na nowych danych...\n",
      "Epoch 1/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 346ms/step - accuracy: 0.4483 - loss: 1.1516 - val_accuracy: 0.5579 - val_loss: 0.9476\n",
      "Epoch 2/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 321ms/step - accuracy: 0.5590 - loss: 0.9729 - val_accuracy: 0.5876 - val_loss: 0.9016\n",
      "Epoch 3/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 343ms/step - accuracy: 0.6330 - loss: 0.8847 - val_accuracy: 0.7144 - val_loss: 0.7676\n",
      "Epoch 4/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 357ms/step - accuracy: 0.6963 - loss: 0.7924 - val_accuracy: 0.6469 - val_loss: 0.8515\n",
      "Epoch 5/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 462ms/step - accuracy: 0.6741 - loss: 0.8382 - val_accuracy: 0.6733 - val_loss: 0.8368\n",
      "Epoch 6/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 512ms/step - accuracy: 0.7109 - loss: 0.7852 - val_accuracy: 0.6277 - val_loss: 0.8627\n",
      "Epoch 7/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 505ms/step - accuracy: 0.6280 - loss: 0.9146 - val_accuracy: 0.7132 - val_loss: 0.7361\n",
      "Epoch 8/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 512ms/step - accuracy: 0.7272 - loss: 0.7405 - val_accuracy: 0.7304 - val_loss: 0.7001\n",
      "Epoch 9/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 502ms/step - accuracy: 0.7518 - loss: 0.6814 - val_accuracy: 0.7540 - val_loss: 0.6632\n",
      "Epoch 10/10\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 505ms/step - accuracy: 0.7712 - loss: 0.6238 - val_accuracy: 0.7715 - val_loss: 0.6168\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - accuracy: 0.7695 - loss: 0.6219\n",
      "\\nDokładność na zbiorze testowym: 0.7715\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 73ms/step\n",
      "\\nRaport klasyfikacji na zbiorze testowym:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "AFTER_RENOVATION       0.69      0.77      0.73      4400\n",
      " DEVELOPER_STATE       0.93      0.91      0.92      4400\n",
      "  FOR_RENOVATION       0.81      0.73      0.77      4303\n",
      "            GOOD       0.66      0.67      0.67      4400\n",
      "\n",
      "        accuracy                           0.77     17503\n",
      "       macro avg       0.78      0.77      0.77     17503\n",
      "    weighted avg       0.78      0.77      0.77     17503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- ARCHITEKTURA I TRENING ---\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "max_words, max_len = 10000, 200  # musi zgadzać się z tokenizacją\n",
    "\n",
    "text_input = Input(shape=(max_len,), name='text_input')\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=128)(text_input)\n",
    "lstm_layer = LSTM(64, recurrent_dropout=0.2)(embedding_layer)\n",
    "dropout_lstm = Dropout(0.4)(lstm_layer)\n",
    "\n",
    "tabular_input = Input(shape=(X_tab_train.shape[1],), name='tabular_input')\n",
    "tabular_dense = Dense(32, activation='relu')(tabular_input)\n",
    "\n",
    "concatenated = Concatenate()([dropout_lstm, tabular_dense])\n",
    "dense1 = Dense(64, activation='relu')(concatenated)\n",
    "dropout_final = Dropout(0.5)(dense1)\n",
    "output = Dense(len(label_names), activation='softmax')(dropout_final)\n",
    "\n",
    "model = Model(inputs=[text_input, tabular_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"\\\\nRozpoczynam trening na nowych danych...\")\n",
    "history = model.fit(\n",
    "    [X_text_train, X_tab_train], y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=([X_text_test, X_tab_test], y_test),\n",
    "    class_weight=class_weight  # odkomentuj, jeśli dysproporcja klas jest duża\n",
    ")\n",
    "\n",
    "# --- OCENA ---\n",
    "loss, accuracy = model.evaluate([X_text_test, X_tab_test], y_test)\n",
    "print(f\"\\\\nDokładność na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "y_pred_proba = model.predict([X_text_test, X_tab_test])\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "print(\"\\\\nRaport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_idx_test, y_pred, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392eedf4-c338-4ca1-8429-4db113af5bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano: model_lstm_stan.keras, tokenizer.json, preprocessor.joblib, label_mapping.json, columns_for_prediction.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- ZAPIS ARTEFAKTÓW ---\n",
    "\n",
    "import joblib, json\n",
    "\n",
    "model.save('model_lstm_stan.keras')\n",
    "\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer.to_json(), ensure_ascii=False))\n",
    "\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "\n",
    "label_mapping = {i: name for i, name in enumerate(label_names)}\n",
    "with open('label_mapping.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({str(k): v for k, v in label_mapping.items()}, f, ensure_ascii=False)\n",
    "\n",
    "columns_for_prediction = numeric_features + categorical_features\n",
    "joblib.dump(columns_for_prediction, 'columns_for_prediction.joblib')\n",
    "\n",
    "print(\"Zapisano: model_lstm_stan.keras, tokenizer.json, preprocessor.joblib, label_mapping.json, columns_for_prediction.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26884c-15e3-47eb-9720-511a7fbe8fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
