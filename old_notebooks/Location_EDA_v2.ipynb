{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff37a9e5-ad6f-49c7-b2c3-e16d186a2878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/13 15:28:08 INFO mlflow.tracking.fluent: Experiment with name 'Investoro_District_Classification_v2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow ustawiony. Eksperyment: 'Investoro_District_Classification_v2'\n",
      "Wczytano dane. Kształt: (20092, 51)\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 1: IMPORT I KONFIGURACJA ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pycaret.classification import (\n",
    "    setup, compare_models, tune_model,\n",
    "    finalize_model, save_model, pull\n",
    ")\n",
    "\n",
    "# Konfiguracja MLflow\n",
    "MLFLOW_EXPERIMENT_NAME = 'Investoro_District_Classification_v2'\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\") # Upewnij się, że adres jest poprawny\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "print(f\"MLflow ustawiony. Eksperyment: '{MLFLOW_EXPERIMENT_NAME}'\")\n",
    "\n",
    "# Wczytanie danych\n",
    "df_original = pd.read_csv('data.csv', sep=',')\n",
    "print(f\"Wczytano dane. Kształt: {df_original.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef18b055-fb08-41d9-9302-ebedcfb38096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oryginalny rozmiar danych: (20092, 51)\n",
      "Rozmiar po usunięciu podstawowych NaN: (19867, 51)\n",
      "Rozmiar po usunięciu outlierów z Price: (19328, 51)\n",
      "Rozmiar po usunięciu outlierów z Area: (18612, 51)\n",
      "\n",
      "Czyszczenie danych zakończone.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 2: CZYSZCZENIE DANYCH ===\n",
    "print(f\"Oryginalny rozmiar danych: {df_original.shape}\")\n",
    "df_cleaned = df_original.copy()\n",
    "\n",
    "# Krok 1: Usunięcie kluczowych braków danych\n",
    "# Usuwamy wiersze, gdzie brakuje absolutnie podstawowych informacji\n",
    "df_cleaned.dropna(subset=['Area', 'Price', 'Location', 'Description'], inplace=True)\n",
    "print(f\"Rozmiar po usunięciu podstawowych NaN: {df_cleaned.shape}\")\n",
    "\n",
    "# Krok 2: Usunięcie outlierów na podstawie ceny (metoda IQR)\n",
    "Q1_price = df_cleaned[\"Price\"].quantile(0.25)\n",
    "Q3_price = df_cleaned[\"Price\"].quantile(0.75)\n",
    "IQR_price = Q3_price - Q1_price\n",
    "df_cleaned = df_cleaned[~((df_cleaned[\"Price\"] < (Q1_price - 1.5 * IQR_price)) | (df_cleaned[\"Price\"] > (Q3_price + 1.5 * IQR_price)))]\n",
    "print(f\"Rozmiar po usunięciu outlierów z Price: {df_cleaned.shape}\")\n",
    "\n",
    "# Krok 3: Usunięcie outlierów na podstawie powierzchni (metoda IQR)\n",
    "Q1_area = df_cleaned[\"Area\"].quantile(0.25)\n",
    "Q3_area = df_cleaned[\"Area\"].quantile(0.75)\n",
    "IQR_area = Q3_area - Q1_area\n",
    "df_cleaned = df_cleaned[~((df_cleaned[\"Area\"] < (Q1_area - 1.5 * IQR_area)) | (df_cleaned[\"Area\"] > (Q3_area + 1.5 * IQR_area)))]\n",
    "print(f\"Rozmiar po usunięciu outlierów z Area: {df_cleaned.shape}\")\n",
    "\n",
    "# Krok 4: Konwersja daty - ważne, by zrobić to przed inżynierią cech\n",
    "df_cleaned['BuiltYear'] = pd.to_datetime(df_cleaned['BuiltYear'], format='%Y', errors='coerce')\n",
    "\n",
    "print(\"\\nCzyszczenie danych zakończone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83a703b-d503-4fe3-9d9e-27b13dcb908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dodano kolumnę 'District'. Liczba unikalnych wartości: 444\n",
      "2. Dodano cechy TF-IDF. Finalny kształt zbioru: (18612, 152)\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 3: INŻYNIERIA CECH (TWORZENIE FINALNEGO ZBIORU) ===\n",
    "df_features = df_cleaned.copy()\n",
    "\n",
    "# --- Krok 3a: Ekstrakcja Dzielnicy (Tworzenie naszego celu - targetu) ---\n",
    "def extract_district(location_str):\n",
    "    if not isinstance(location_str, str): return np.nan\n",
    "    parts = [part.strip() for part in location_str.split(',')]\n",
    "    if len(parts) >= 3: return f\"{parts[1]}, {parts[2]}\" # Np. \"Warszawa, Mokotów\"\n",
    "    elif len(parts) == 2: return parts[1] # Np. \"Kraków\"\n",
    "    else: return parts[0]\n",
    "\n",
    "df_features['District'] = df_features['Location'].apply(extract_district)\n",
    "df_features.dropna(subset=['District'], inplace=True)\n",
    "print(f\"1. Dodano kolumnę 'District'. Liczba unikalnych wartości: {df_features['District'].nunique()}\")\n",
    "\n",
    "# --- Krok 3b: Tworzenie cech TF-IDF z opisu ogłoszenia ---\n",
    "vectorizer = TfidfVectorizer(max_features=100, ngram_range=(1, 2), min_df=5, max_df=0.95)\n",
    "\n",
    "# Aby uniknąć problemów z indeksami przy łączeniu, resetujemy je\n",
    "df_features.reset_index(drop=True, inplace=True)\n",
    "tfidf_features = vectorizer.fit_transform(df_features['Description']) # .fillna('') już niepotrzebne\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=['des_tfidf_' + name for name in feature_names])\n",
    "\n",
    "# Łączymy wszystko w jeden finalny DataFrame\n",
    "df_final = pd.concat([df_features, tfidf_df], axis=1)\n",
    "print(f\"2. Dodano cechy TF-IDF. Finalny kształt zbioru: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02688f84-3271-457a-a7d5-e8fa9e317221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usunięto 132 rzadkich dzielnic. Pozostało 18430 wierszy.\n",
      "Liczba klas (dzielnic) do predykcji: 312\n",
      "\n",
      "Podział danych -> Treningowe: (16587, 152), Testowe: (1843, 152)\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 4: PRZYGOTOWANIE DO MODELOWANIA ===\n",
    "\n",
    "# --- Krok 4a: Filtrowanie rzadkich dzielnic (klas) ---\n",
    "MIN_SAMPLES_PER_DISTRICT = 3\n",
    "district_counts = df_final['District'].value_counts()\n",
    "districts_to_remove = district_counts[district_counts < MIN_SAMPLES_PER_DISTRICT].index\n",
    "df_model_ready = df_final[~df_final['District'].isin(districts_to_remove)].copy() # .copy() dla bezpieczeństwa\n",
    "\n",
    "print(f\"Usunięto {len(districts_to_remove)} rzadkich dzielnic. Pozostało {len(df_model_ready)} wierszy.\")\n",
    "print(f\"Liczba klas (dzielnic) do predykcji: {df_model_ready['District'].nunique()}\")\n",
    "\n",
    "# --- Krok 4b: Podział na zbiór treningowy i testowy (holdout) ---\n",
    "data_train = df_model_ready.sample(frac=0.9, random_state=1122)\n",
    "data_test = df_model_ready.drop(data_train.index)\n",
    "print(f\"\\nPodział danych -> Treningowe: {data_train.shape}, Testowe: {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c31e14a-2539-4e0e-b9e9-b10f5b77feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynam setup PyCaret (bez interakcji z MLflow)...\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8               Ignore features   \n",
      "9              Numeric features   \n",
      "10                Date features   \n",
      "11         Categorical features   \n",
      "12     Rows with missing values   \n",
      "13                   Preprocess   \n",
      "14              Imputation type   \n",
      "15           Numeric imputation   \n",
      "16       Categorical imputation   \n",
      "17     Maximum one-hot encoding   \n",
      "18              Encoding method   \n",
      "19               Fold Generator   \n",
      "20                  Fold Number   \n",
      "21                     CPU Jobs   \n",
      "22                      Use GPU   \n",
      "23               Log Experiment   \n",
      "24              Experiment Name   \n",
      "25                          USI   \n",
      "\n",
      "                                                Value  \n",
      "0                                                1122  \n",
      "1                                            District  \n",
      "2                                          Multiclass  \n",
      "3   Gorzowski: 0, Gorzowski, Bogdaniec: 1, Gorzows...  \n",
      "4                                        (18430, 152)  \n",
      "5                                        (18430, 181)  \n",
      "6                                        (16587, 181)  \n",
      "7                                         (1843, 181)  \n",
      "8                                                  11  \n",
      "9                                                 104  \n",
      "10                                                  1  \n",
      "11                                                  8  \n",
      "12                                             100.0%  \n",
      "13                                               True  \n",
      "14                                             simple  \n",
      "15                                               mean  \n",
      "16                                               mode  \n",
      "17                                                 25  \n",
      "18                                               None  \n",
      "19                                    StratifiedKFold  \n",
      "20                                                 10  \n",
      "21                                                 -1  \n",
      "22                                              False  \n",
      "23                                              False  \n",
      "24                                   clf-default-name  \n",
      "25                                               df8f  \n",
      "\n",
      "Setup PyCaret zakończony pomyślnie.\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 5: SETUP PYCARET (BEZ LOGOWANIA) ===\n",
    "\n",
    "print(\"\\nRozpoczynam setup PyCaret (bez interakcji z MLflow)...\")\n",
    "\n",
    "# Definicja list cech\n",
    "numeric_features = [c for c in data_train.columns if c.startswith('des_tfidf_')] + ['Area', 'NumberOfRooms', 'Floor', 'Floors']\n",
    "categorical_features = ['BuildingType', 'BuildingCondition', 'TypeOfMarket', 'OwnerType', 'Type', 'OfferFrom', 'VoivodeshipNumber', 'CountyNumber']\n",
    "date_features = ['BuiltYear']\n",
    "\n",
    "# Automatyczne usunięcie cech, których może nie być\n",
    "numeric_features = [f for f in numeric_features if f in data_train.columns]\n",
    "categorical_features = [f for f in categorical_features if f in data_train.columns]\n",
    "\n",
    "# Lista ignorowanych cech\n",
    "ignore_features = [\n",
    "    'SaleId', 'OriginalId', 'Location', 'Description', 'Title', 'Link', 'Price'\n",
    "] + [c for c in data_train.columns if c.startswith('Date') and c != 'BuiltYear']\n",
    "\n",
    "s = setup(\n",
    "    data=data_train,\n",
    "    test_data=data_test,\n",
    "    target='District',\n",
    "    session_id=1122,\n",
    "    \n",
    "    # KLUCZOWA ZMIANA: Całkowicie wyłączamy logowanie na tym etapie\n",
    "    log_experiment=False, \n",
    "    \n",
    "    numeric_features=numeric_features,\n",
    "    categorical_features=categorical_features,\n",
    "    date_features=date_features,\n",
    "    ignore_features=ignore_features,\n",
    "    \n",
    "    # Zostawiamy dla bezpieczeństwa\n",
    "    html=False,\n",
    "    verbose=True # Ustawiamy na True, aby zobaczyć tabelę z podsumowaniem setup\n",
    ")\n",
    "print(\"\\nSetup PyCaret zakończony pomyślnie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10be3044-2764-4158-8071-e242ae3bfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mlflow.active_run():\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3d9c7f-e47d-4135-8223-54813468e2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęto run w MLflow: c11fad3d1ef04f39b8f5648c43675ef3\n",
      "Rozpoczynam porównywanie modeli (wyniki będą logowane)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porównanie modeli zakończone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Najlepszy zidentyfikowany model: []\n"
     ]
    }
   ],
   "source": [
    "# === SEKCJA 6: TRENING I LOGOWANIE DO MLFLOW ===\n",
    "\n",
    "# Upewnij się, że nie ma aktywnego runu\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run(run_name=\"District_Classification_Training_Run\") as run:\n",
    "    print(f\"Rozpoczęto run w MLflow: {run.info.run_id}\")\n",
    "    print(\"Rozpoczynam porównywanie modeli (wyniki będą logowane)...\")\n",
    "    \n",
    "    # compare_models wykryje aktywny run i zaloguje do niego metryki i modele\n",
    "    best_model = compare_models(sort='F1')\n",
    "    \n",
    "    print(\"\\nPorównanie modeli zakończone.\")\n",
    "    \n",
    "    # Wyciągnij i wyświetl tabelę\n",
    "    all_models_metrics = pull()\n",
    "    display(all_models_metrics)\n",
    "    \n",
    "    # Zaloguj tabelę jako artefakt\n",
    "    all_models_metrics.to_csv(\"compare_models_results.csv\")\n",
    "    mlflow.log_artifact(\"compare_models_results.csv\")\n",
    "    \n",
    "    print(f\"\\nNajlepszy zidentyfikowany model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086d87f0-6b5b-4666-b865-3dda23510193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynam tuning najlepszego modelu...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Estimator [] does not have the required fit() method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === SEKCJA 7: TUNING I FINALIZACJA ===\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Uruchom w ramach tego samego bloku 'with' lub po nim,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# PyCaret powinien zalogować do ostatniego aktywnego runu.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRozpoczynam tuning najlepszego modelu...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m tune_model(best_model, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTuning zakończony. Wyniki po tuningu:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m display(pull())\n",
      "File \u001b[1;32m~\\.conda\\envs\\projekt1\\Lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\projekt1\\Lib\\site-packages\\pycaret\\classification\\functional.py:1208\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1019\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1038\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CURRENT_EXPERIMENT\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1209\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1210\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1212\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1213\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1214\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1215\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1216\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1217\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1218\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1219\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1220\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1221\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1222\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1223\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1224\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1225\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1226\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1227\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1228\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\projekt1\\Lib\\site-packages\\pycaret\\classification\\oop.py:1558\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1369\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1559\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1560\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1563\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1564\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1565\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1566\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1567\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1568\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1569\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1570\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1571\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1572\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1573\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1574\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1575\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1576\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1577\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1578\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\projekt1\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1996\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;66;03m# Check for estimator\u001b[39;00m\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not have the required fit() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1998\u001b[0m     )\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;66;03m# checking fold parameter\u001b[39;00m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   2002\u001b[0m     \u001b[38;5;28mtype\u001b[39m(fold) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_sklearn_cv_generator(fold)\n\u001b[0;32m   2003\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Estimator [] does not have the required fit() method."
     ]
    }
   ],
   "source": [
    "# === SEKCJA 7: TUNING I FINALIZACJA ===\n",
    "# Uruchom w ramach tego samego bloku 'with' lub po nim,\n",
    "# PyCaret powinien zalogować do ostatniego aktywnego runu.\n",
    "\n",
    "print(\"\\nRozpoczynam tuning najlepszego modelu...\")\n",
    "tuned_model = tune_model(best_model, n_iter=25, sort='F1')\n",
    "print(\"\\nTuning zakończony. Wyniki po tuningu:\")\n",
    "display(pull())\n",
    "\n",
    "print(\"\\nFinalizowanie modelu...\")\n",
    "final_model = finalize_model(tuned_model)\n",
    "print(f\"Model sfinalizowany: {final_model}\")\n",
    "\n",
    "save_model(final_model, 'district_classifier_final_model_v2')\n",
    "print(\"\\nFinalny model został zapisany do pliku.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d700081-2fa9-4497-9968-977003f5687a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
