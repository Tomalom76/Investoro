{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36406e2a-cf5d-4a0e-afb0-2fcda6ad5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: importy i konfiguracja\n",
    "import os, re, math, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Deterministyczność (opcjonalnie)\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b878b9-6d53-4f20-aa21-437fd153ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytano (bez nagłówka) (1467263, 56) z: Data_state_LSTM_predicted_full_v4_FINAL.csv\n",
      "Nagłówek ustawiony na podstawie wiersza: 0\n",
      "Kolumny (po korekcie nagłówka): ['88', 'nan', '14', 'Mieszkanie trzypokojowe na sprzedaż', 'Mieszkanie o powierzchni 73m2 znajduje się na 3 piętrze bloku z cegły z 2005 roku, w doskonałej lokalizacji osiedla Bojary, zaledwie 2 minuty od Pałacu Branickich, co sprawia, że jest to ścisłe centrum miasta. Mieszkanie zostało urządzone w swojskim klimacie, co czyni je wyjątkowym i wyróżnia się spośród innych dostępnych na rynku. Wejście do mieszkania jest wygodne i szerokie, a dodatkowo została zamontowana szafa wnękowa na okrycia wierzchnie, co zapewnia praktyczne rozwiązanie na przechowywanie ubrań i innych przedmiotów. Zabudowa kuchenna w mieszkaniu jest wyjątkowo zaakcentowana i wykonana z płytek z glazury, co nadaje jej wiejski klimat. Jest to unikalne rozwiązanie, które wyróżnia się spośród innych standardowych kuchni. Dodatkowo, zabudowa kuchenna utrzymana jest w nienagannym stanie, co oznacza, że jest dobrze utrzymana i nie wymaga większych nakładów finansowych na remont czy modernizację. Taki detal wnętrza dodaje charakteru i osobowości całemu mieszkaniu, tworząc przytulną atmosferę wiejskiego stylu co dodaje mu charakteru. Mieszkanie posiada dwie oddzielne sypialnie, co zapewnia prywatność i komfort mieszkańcom. Salon posiada wyjście na balkon, który stanowi idealne miejsce do odpoczynku i relaksu na świeżym powietrzu. Mieszkanie jest dwustronne, co oznacza, że posiada okna na dwie strony, co zapewnia optymalne doświetlenie i przewiewność pomieszczeń. W mieszkaniu znajduje się wydzielona strefa wypoczynkowa, która jest dostępna tylko dla mieszkańców, co gwarantuje prywatność i spokój. Dodatkowo, łazienka z WC jest osobna dla gości i dla mieszkańców co jest wygodnym rozwiązaniem dla domowników. Kuchnia z jadalnią tworzą jedną otwartą dużą przestrzeń, co sprzyja integracji i swobodnemu poruszaniu się między tymi dwoma obszarami. To mieszkanie jest idealne dla osób poszukujących czegoś innego i nietuzinkowego, które cenią sobie wyjątkowy styl i atmosferę. Okna dachowe w mieszkaniu są dość duże, co przyczynia się do obfitości naturalnego światła w pomieszczeniach. Dzięki temu mieszkanie jest jasne i przyjemne, a także pozwala zaoszczędzić na kosztach energii elektrycznej. Taka aranżacja przestrzeni sprawia, że mieszkanie staje się bardziej przestronne i przyjazne dla mieszkańców. Lokalizacja mieszkania jest dogodna, znajduje się w bliskiej odległości od sklepów, restauracji, szkół i przedszkoli. Mieszkanie jest przestronne i funkcjonalne, co pozwala na swobodne urządzenie przestrzeni według własnych preferencji. To doskonała oferta dla osób poszukujących mieszkania z wydzieloną strefą wypoczynkową i osobną łazienką, które zapewnią im komfort i prywatność. To doskonała oferta dla osób, które cenią sobie unikalne i oryginalne rozwiązania w aranżacji wnętrz, a także chcą mieszkać w miejscu utrzymanym w nienagannym stanie. Dodatkowo istnieje możliwość zakupu garażu o powierzchni 15m2, który znajduje się przy wejściu do klatki schodowej. To świetna opcja, ponieważ zapewnia dodatkowe miejsce parkingowe dla dwóch samochodów. Posiadanie garażu przy wejściu do klatki ułatwia dostęp do pojazdów i zapewnia wygodę podczas wsiadania i wysiadania z auta. To doskonałe rozwiązanie dla rodzin posiadających dwa samochody lub dla osób, które potrzebują dodatkowego miejsca parkingowego dla gości. Zakup garażu jest opcjonalny, ale może być bardzo praktycznym udogodnieniem dla mieszkańców. Cena garażu 55 000 tyś W ramach usługi rozliczamy dla klienta zużycie gazu, wody, energii elektrycznej oraz innych opłat związanych z eksploatacją nieruchomości. Nasze transakcje są ubezpieczone. Chcąc zapewnić Państwu kompleksową obsługę przy zakupie nieruchomości oddajemy do Państwa dyspozycji Eksperta Finansowego, który BEZPŁATNIE: – Spotka się w dogodnym dla Państwa miejscu i terminie – Wyliczy zdolność kredytową w kilkunastu bankach – Porówna aktualne oferty banków i pomoże wybrać najkorzystniejszą – Wynegocjuje za Państwa atrakcyjne warunki finansowania – Przeprowadzi całą procedurę kredytową i pomoże w przygotowaniu formalności Zapraszamy do kontaktu Biuro Lider Nieruchomości ul. Św. Rocha 10 lok 117 Białystok, email: biuro@lidskontaktuj się, www.lidernieruchomosci.com Informacje dotyczące ogłoszenia są podane przez właściciela, mają charakter wyłącznie informacyjny mogą podlegać aktualizacji. Oferta dotycząca nieruchomości stanowi zaproszenie do rokowań zgodnie z art. 71 Kodeksu Cywilnego i nie stanowi oferty określonej w art. 66 kodeksu cywilnego i następnych KC. Oferujący nie odpowiada za ewentualne błędy lub nieaktualność ogłoszenia. Jeśli zakup tej nieruchomości wiąże się ze sprzedażą innej - proszę o informację, a na pewno pomogę Państwu w realizacji takiej transakcji. Zapraszam do kontaktu. Wszelkie prawa zastrzeżone! Kopiowanie, powielanie i wykorzystywanie zdjęć oraz filmów bez zgody autora zabronione. Dz. U. 94 Nr 24 poz. 83, sprost.: Dz. U. 94 Nr 43 poz. 170 Oferta wysłana z programu dla biur nieruchomości ASARI CRM (asaricrm.com) Numer oferty: 1196/5835/OMS', '73', '766500', 'nan', 'nan', 'nan', '10500', '3', '2005', 'Mieszkania', 'Blok', 'nan', 'Agencja', '3', 'nan', 'Wtórny']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Nie znaleziono kolumny lokalizacji (szukano: ['predicted_loc', 'predict_loc', 'predictedloc', 'predictloc']). Podobne: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     61\u001b[39m state_name, state_hints = unpack(state_res)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loc_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNie znaleziono kolumny lokalizacji (szukano: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     65\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPodobne: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc_hints\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNie znaleziono kolumny stanu (szukano: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m). \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     68\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPodobne: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_hints\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Nie znaleziono kolumny lokalizacji (szukano: ['predicted_loc', 'predict_loc', 'predictedloc', 'predictloc']). Podobne: []"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import get_close_matches\n",
    "\n",
    "PATH = 'Data_state_LSTM_predicted_full_v4_FINAL.csv'\n",
    "\n",
    "# 1) Wczytaj bez nagłówka (plik z LSTM ma separator ';')\n",
    "df_raw = pd.read_csv(PATH, sep=';', encoding='utf-8-sig', header=None)\n",
    "print(f'Wczytano (bez nagłówka) {df_raw.shape} z: {PATH}')\n",
    "\n",
    "# 2) Znajdź wiersz nagłówka: szukamy takiego, który zawiera tokeny przewidywanych kolumn\n",
    "header_tokens = {'predict_state', 'predicted_state', 'predict_loc', 'predicted_loc', 'saleid', 'title', 'description'}\n",
    "header_idx = None\n",
    "for i in range(min(50, len(df_raw))):  # skan 50 pierwszych wierszy\n",
    "    row_vals = df_raw.iloc[i].astype(str).str.lower().str.strip()\n",
    "    if any(tok in set(row_vals.values) for tok in header_tokens):\n",
    "        header_idx = i\n",
    "        break\n",
    "\n",
    "if header_idx is None:\n",
    "    # fallback: jeśli nie wykryto, spróbuj użyć pierwszego wiersza jako nagłówka\n",
    "    header_idx = 0\n",
    "\n",
    "# 3) Ustaw nagłówek z wybranego wiersza i usuń go z danych\n",
    "new_columns = df_raw.iloc[header_idx].astype(str).tolist()\n",
    "df = df_raw.drop(index=header_idx).reset_index(drop=True)\n",
    "df.columns = new_columns\n",
    "print('Nagłówek ustawiony na podstawie wiersza:', header_idx)\n",
    "print('Kolumny (po korekcie nagłówka):', list(df.columns)[:20])\n",
    "\n",
    "# 4) Normalizacja nazw i mapowanie kolumn lokalizacji/stanu budynku\n",
    "def canon(s: str) -> str:\n",
    "    s = str(s)\n",
    "    return ''.join(ch for ch in s.lower() if ch.isalnum() or ch == '_')\n",
    "\n",
    "col_map = {canon(c): c for c in df.columns}\n",
    "\n",
    "loc_candidates   = ['predicted_loc', 'predict_loc', 'predictedloc', 'predictloc']\n",
    "state_candidates = ['predict_state', 'predicted_state', 'predictstate', 'predictedstate']\n",
    "\n",
    "def resolve(col_map, candidates):\n",
    "    # najpierw próbuj pełnych kandydatów\n",
    "    for cand in candidates:\n",
    "        key = canon(cand)\n",
    "        if key in col_map:\n",
    "            return col_map[key]\n",
    "    # fuzzy podpowiedzi (weź pierwszy kandydat jako wzorzec)\n",
    "    base = canon(candidates)\n",
    "    close = get_close_matches(base, list(col_map.keys()), n=3, cutoff=0.6)\n",
    "    hints = [col_map[k] for k in close]\n",
    "    return None, hints\n",
    "\n",
    "def unpack(res):\n",
    "    if isinstance(res, tuple):\n",
    "        return None, res[1]\n",
    "    return res, []\n",
    "\n",
    "loc_res = resolve(col_map, loc_candidates)\n",
    "state_res = resolve(col_map, state_candidates)\n",
    "loc_name, loc_hints     = unpack(loc_res)\n",
    "state_name, state_hints = unpack(state_res)\n",
    "\n",
    "if loc_name is None:\n",
    "    raise ValueError(f'Nie znaleziono kolumny lokalizacji (szukano: {loc_candidates}). '\n",
    "                     f'Podobne: {loc_hints}')\n",
    "if state_name is None:\n",
    "    raise ValueError(f'Nie znaleziono kolumny stanu (szukano: {state_candidates}). '\n",
    "                     f'Podobne: {state_hints}')\n",
    "\n",
    "# 5) Przemianuj na kanoniczne nazwy używane dalej w pipeline\n",
    "df = df.rename(columns={loc_name: 'Predicted_Loc', state_name: 'Predict_State'})\n",
    "df['Predicted_Loc'] = df['Predicted_Loc'].astype(str).fillna('Brak Danych')\n",
    "df['Predict_State'] = df['Predict_State'].astype(str).fillna('Brak Danych')\n",
    "\n",
    "print('Gotowe nazwy:', {'Predicted_Loc': loc_name, 'Predict_State': state_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5ec09-cb5a-4357-aba0-0f0f72b7e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: inżynieria cech (liczbowe + porządkowe)\n",
    "df_proc = df.copy()\n",
    "\n",
    "# Cechy liczbowe\n",
    "num_cols = ['Area','NumberOfRooms','Floor','Floors']\n",
    "for c in num_cols:\n",
    "    if c in df_proc.columns:\n",
    "        df_proc[c] = pd.to_numeric(df_proc[c], errors='coerce')\n",
    "\n",
    "# BuiltYear -> BuildingAge\n",
    "if 'BuiltYear' in df_proc.columns:\n",
    "    by = pd.to_numeric(df_proc['BuiltYear'], errors='coerce')\n",
    "    median_year = by.dropna().median() if not np.isnan(by.dropna().median()) else 2000\n",
    "    by = by.fillna(median_year)\n",
    "    year_int = by.astype(int)\n",
    "    current_year = datetime.now().year\n",
    "    df_proc['BuildingAge'] = (current_year - year_int).clip(lower=0, upper=200)\n",
    "else:\n",
    "    df_proc['BuildingAge'] = np.nan\n",
    "\n",
    "# docelowe kolumny liczbowe do modelu\n",
    "numeric_features = ['Area','NumberOfRooms','Floor','Floors','BuildingAge']\n",
    "\n",
    "# Cechy kategoryczne (priorytetowe)\n",
    "cat_priority = ['Predict_State','Predicted_Loc']\n",
    "\n",
    "# Dodatkowe kategorie (opcjonalnie, jeśli istnieją)\n",
    "cat_optional = [c for c in ['BuildingType','TypeOfMarket','Type','OfferFrom','OwnerType'] if c in df_proc.columns]\n",
    "\n",
    "categorical_features = cat_priority + cat_optional\n",
    "\n",
    "# Czyszczenie braków\n",
    "for c in categorical_features:\n",
    "    df_proc[c] = df_proc[c].astype(str).fillna('unknown').replace({'nan':'unknown','None':'unknown'})\n",
    "\n",
    "# Target\n",
    "df_proc['Price'] = pd.to_numeric(df_proc['Price'], errors='coerce')\n",
    "df_proc = df_proc.dropna(subset=['Price','Area'])  # minimalne wymagania\n",
    "print('Dane po wstępnym przetwarzaniu:', df_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bd399-19b6-4e26-928c-d35702ffdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: split + tf.data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = numeric_features + categorical_features\n",
    "target = 'Price'\n",
    "\n",
    "train_df, val_df = train_test_split(df_proc[features + [target]], test_size=0.2, random_state=SEED)\n",
    "\n",
    "def df_to_ds(frame, shuffle=False, batch_size=1024):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((\n",
    "        {col: frame[col].values for col in features},\n",
    "        frame[target].values.astype('float32')\n",
    "    ))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(frame), seed=SEED)\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = df_to_ds(train_df, shuffle=True)\n",
    "val_ds   = df_to_ds(val_df, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd02987-9516-4bad-8d85-83de7a76c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: preprocessing layers\n",
    "# Normalization dla liczb\n",
    "normalizers = {}\n",
    "for c in numeric_features:\n",
    "    norm = layers.Normalization(axis=None)\n",
    "    x = train_df[c].values.astype('float32').reshape(-1,1)\n",
    "    norm.adapt(x)\n",
    "    normalizers[c] = norm\n",
    "\n",
    "# StringLookup + Embedding dla kategorii\n",
    "lookup_layers = {}\n",
    "embed_layers  = {}\n",
    "embed_dims = {}\n",
    "\n",
    "def make_string_lookup(name, train_series):\n",
    "    lk = layers.StringLookup(output_mode='int', num_oov_indices=1)\n",
    "    lk.adapt(train_series.astype(str).values)\n",
    "    return lk\n",
    "\n",
    "def suggest_embed_dim(cardinality):\n",
    "    # prosta heurystyka\n",
    "    return int(min(50, max(4, round(np.sqrt(cardinality)))))\n",
    "\n",
    "for c in categorical_features:\n",
    "    lk = make_string_lookup(c, train_df[c])\n",
    "    vocab_size = lk.vocabulary_size()\n",
    "    dim = suggest_embed_dim(vocab_size)\n",
    "    emb = layers.Embedding(input_dim=vocab_size+1, output_dim=dim)  # +1 zapasowo\n",
    "    lookup_layers[c] = lk\n",
    "    embed_layers[c]  = emb\n",
    "    embed_dims[c]    = dim\n",
    "\n",
    "print({c: (lookup_layers[c].vocabulary_size(), embed_dims[c]) for c in categorical_features})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ee512-d4cf-4488-a9a7-f38ca0357c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: model Keras (regresja wide & deep)\n",
    "inputs = {}\n",
    "num_tensors = []\n",
    "for c in numeric_features:\n",
    "    inp = layers.Input(shape=(1,), name=c, dtype=tf.float32)\n",
    "    inputs[c] = inp\n",
    "    x = normalizers[c](inp)\n",
    "    num_tensors.append(x)\n",
    "\n",
    "cat_tensors = []\n",
    "for c in categorical_features:\n",
    "    inp = layers.Input(shape=(1,), name=c, dtype=tf.string)\n",
    "    inputs[c] = inp\n",
    "    idx = lookup_layers[c](inp)\n",
    "    emb = embed_layers[c](idx)\n",
    "    emb = layers.Reshape((embed_dims[c],))(emb)  # (batch, dim)\n",
    "    cat_tensors.append(emb)\n",
    "\n",
    "# Fuzja\n",
    "x = layers.Concatenate()(num_tensors + cat_tensors)\n",
    "\n",
    "# Głowica regresyjna\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "output = layers.Dense(1, name='price')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='mse',\n",
    "              metrics=[keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                       keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802e65e-8d51-4cd1-b8b6-e872ecd8459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: trening\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "csv = keras.callbacks.CSVLogger('training_regression_keras.csv', append=False)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[es, rlr, csv]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7281401-b745-4fec-9dc7-d18d6859093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: ocena + zapis\n",
    "eval_res = model.evaluate(val_ds, verbose=0)\n",
    "print({'loss_mse': eval_res, 'mae': eval_res[1], 'rmse': eval_res[13]})\n",
    "\n",
    "SAVE_PATH = 'price_regressor_wide_deep.keras'\n",
    "model.save(SAVE_PATH)\n",
    "print(f'Zapisano model: {SAVE_PATH}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a89e0-1be3-40b8-9abb-f36e2297bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: inferencja na nowych danych\n",
    "def predict_on_csv(path, batch_size=2048):\n",
    "    df_new = pd.read_csv(path, sep=None, engine='python', low_memory=False)\n",
    "    # wymagane kolumny\n",
    "    need = set(numeric_features + categorical_features)\n",
    "    missing = [c for c in need if c not in df_new.columns]\n",
    "    for c in missing:\n",
    "        if c in categorical_features:\n",
    "            df_new[c] = 'unknown'\n",
    "        else:\n",
    "            df_new[c] = np.nan\n",
    "\n",
    "    # building age jeżeli trzeba\n",
    "    if 'BuildingAge' in numeric_features and 'BuildingAge' not in df_new.columns:\n",
    "        if 'BuiltYear' in df_new.columns:\n",
    "            by = pd.to_numeric(df_new['BuiltYear'], errors='coerce')\n",
    "            med = by.dropna().median() if not np.isnan(by.dropna().median()) else 2000\n",
    "            by = by.fillna(med).astype(int)\n",
    "            df_new['BuildingAge'] = (datetime.now().year - by).clip(lower=0, upper=200)\n",
    "        else:\n",
    "            df_new['BuildingAge'] = np.nan\n",
    "\n",
    "    # typy\n",
    "    for c in numeric_features:\n",
    "        df_new[c] = pd.to_numeric(df_new[c], errors='coerce')\n",
    "    for c in categorical_features:\n",
    "        df_new[c] = df_new[c].astype(str).fillna('unknown').replace({'nan':'unknown','None':'unknown'})\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices({col: df_new[col].values for col in numeric_features + categorical_features})\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    preds = model.predict(ds, verbose=0).reshape(-1)\n",
    "    out = df_new.copy()\n",
    "    out['PredictedPrice'] = preds\n",
    "    return out\n",
    "\n",
    "# przykład:\n",
    "# preds_df = predict_on_csv('Data_state_LSTM_predicted_full_v4_FINAL.csv')\n",
    "# preds_df[['SaleId','Price','Predicted_Loc','Predict_State','PredictedPrice']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df32fc-7677-4bde-82fc-c8191d21e4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
