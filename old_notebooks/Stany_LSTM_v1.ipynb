{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7980b1-fc44-46e5-a85d-1f93220aac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ai\\AppData\\Local\\miniconda3\\envs\\projekt_stan\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Wyłączenie ostrzeżeń, które mogą się pojawiać przy wczytywaniu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f726db-e1c8-4621-92cd-2c82a1be6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytuję plik: saleflats_2024_dateAdded_polska.csv\n",
      "OSTRZEŻENIE: Pominięto łącznie 73512 uszkodzonych wierszy.\n",
      "Wczytuję plik: saleflats_2024_newestDate_polska.csv\n",
      "OSTRZEŻENIE: Pominięto łącznie 69269 uszkodzonych wierszy.\n",
      "Dane wczytane i połączone. Kształt: (760765, 53)\n"
     ]
    }
   ],
   "source": [
    "# --- WCZYTYWANIE DANYCH ---\n",
    "def read_robust_csv_no_header(filepath, header):\n",
    "    import csv\n",
    "    print(f\"Wczytuję plik: {filepath}\")\n",
    "    data_rows = []\n",
    "    malformed_count = 0\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        reader = csv.reader(f)\n",
    "        expected_col_count = len(header)\n",
    "        for i, row in enumerate(reader, start=1):\n",
    "            if len(row) == expected_col_count:\n",
    "                data_rows.append(row)\n",
    "            else:\n",
    "                malformed_count += 1\n",
    "    if malformed_count > 0:\n",
    "        print(f\"OSTRZEŻENIE: Pominięto łącznie {malformed_count} uszkodzonych wierszy.\")\n",
    "    return pd.DataFrame(data_rows, columns=header)\n",
    "\n",
    "CORRECT_HEADER = ['SaleId', 'OriginalId', 'PortalId', 'Title', 'Description', 'Area', 'Price', 'OfferPrice', 'RealPriceAfterRenovation', 'OriginalPrice', 'PricePerSquareMeter', 'NumberOfRooms', 'BuiltYear', 'Type', 'BuildingType', 'BuildingCondition', 'OfferFrom', 'Floor', 'Floors', 'TypeOfMarket', 'OwnerType', 'DateAddedToDatabase', 'DateAdded', 'DateLastModification', 'DateLastRaises', 'NewestDate', 'AvailableFrom', 'Link', 'Phone', 'MainImage', 'OtherImages', 'NumberOfDuplicates', 'NumberOfRaises', 'NumberOfModifications', 'IsDuplicatePriceLower', 'IsDuplicatePrivateOwner', 'Score', 'ScorePrecision', 'CommunityScore', 'NumberOfCommunityComments', 'NumberOfCommunityOpinions', 'Archive', 'Location', 'VoivodeshipNumber', 'CountyNumber', 'CommunityNumber', 'KindNumber', 'RegionNumber', 'SubRegionNumber', 'StreetNumber', 'EncryptedId', 'PredictedRenovation', 'LocationPath']\n",
    "if len(CORRECT_HEADER) != 53:\n",
    "    CORRECT_HEADER.extend([f'UnknownCol_{i}' for i in range(53 - len(CORRECT_HEADER))])\n",
    "\n",
    "df_added = read_robust_csv_no_header('saleflats_2024_dateAdded_polska.csv', header=CORRECT_HEADER)\n",
    "df_newest = read_robust_csv_no_header('saleflats_2024_newestDate_polska.csv', header=CORRECT_HEADER)\n",
    "\n",
    "for df_temp in [df_added, df_newest]:\n",
    "    df_temp['SaleId'] = pd.to_numeric(df_temp['SaleId'], errors='coerce')\n",
    "df_added.dropna(subset=['SaleId'], inplace=True)\n",
    "df_newest.dropna(subset=['SaleId'], inplace=True)\n",
    "for df_temp in [df_added, df_newest]:\n",
    "    df_temp['SaleId'] = df_temp['SaleId'].astype(int)\n",
    "\n",
    "df = pd.merge(df_added, df_newest, on='SaleId', how='outer', suffixes=('_added', '_newest'))\n",
    "for col in df.columns:\n",
    "    if col.endswith('_added'):\n",
    "        base_col_name = col.replace('_added', '')\n",
    "        newest_col_name = f\"{base_col_name}_newest\"\n",
    "        if newest_col_name in df.columns:\n",
    "            df[col] = df[col].fillna(df[newest_col_name])\n",
    "            df.rename(columns={col: base_col_name}, inplace=True)\n",
    "            df.drop(columns=[newest_col_name], inplace=True)\n",
    "\n",
    "print(f\"Dane wczytane i połączone. Kształt: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6d7bee-c234-4ce4-b910-347c37c2b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Krok 1: Przygotowanie danych (typy i reguły) ---\n",
      "Liczba wierszy przed balansowaniem: 135797\n",
      "Rozkład klas PRZED zbalansowaniem:\n",
      "BuildingCondition\n",
      "DEVELOPER_STATE     135044\n",
      "GOOD                   500\n",
      "AFTER_RENOVATION       161\n",
      "FOR_RENOVATION          92\n",
      "Name: count, dtype: int64\n",
      "Rozkład klas PO zbalansowaniu:\n",
      "BuildingCondition\n",
      "DEVELOPER_STATE     10000\n",
      "GOOD                  500\n",
      "AFTER_RENOVATION      161\n",
      "FOR_RENOVATION         92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Krok 3: Uproszczone przygotowanie danych do modelu ---\n"
     ]
    }
   ],
   "source": [
    "# --- KROK 1: PRZYGOTOWANIE DANYCH ---\n",
    "print(\"--- Krok 1: Przygotowanie danych (typy i reguły) ---\")\n",
    "data_to_process = df.copy()\n",
    "data_to_process.replace(['NULL', ''], np.nan, inplace=True)\n",
    "data_to_process['BuiltYear'] = pd.to_datetime(data_to_process['BuiltYear'], errors='coerce')\n",
    "data_to_process.loc[data_to_process['TypeOfMarket'] == 'pierwotny', 'BuildingCondition'] = 'DEVELOPER_STATE'\n",
    "data_to_process.loc[data_to_process['BuiltYear'].dt.year >= 2024, 'BuildingCondition'] = 'DEVELOPER_STATE'\n",
    "\n",
    "# Filtrowanie - potrzebujemy tylko opisu i etykiety\n",
    "data = data_to_process.dropna(subset=['BuildingCondition', 'Description']).copy()\n",
    "print(f\"Liczba wierszy przed balansowaniem: {len(data)}\")\n",
    "print(\"Rozkład klas PRZED zbalansowaniem:\")\n",
    "print(data['BuildingCondition'].value_counts())\n",
    "\n",
    "# --- KROK 2: RĘCZNE BALANSOWANIE (UNDERSAMPLING) ---\n",
    "# Ustawiamy docelową liczbę próbek. Można ją dostosować.\n",
    "# Weźmy np. 10000, jeśli klasy na to pozwalają, lub mniejszą wartość.\n",
    "target_samples = 10000 \n",
    "\n",
    "balanced_dfs = []\n",
    "for condition_class in data['BuildingCondition'].unique():\n",
    "    class_df = data[data['BuildingCondition'] == condition_class]\n",
    "    n_samples = min(len(class_df), target_samples) # Bierzemy max tyle, ile jest lub target\n",
    "    resampled_df = resample(class_df, \n",
    "                            replace=False, \n",
    "                            n_samples=n_samples, \n",
    "                            random_state=42)\n",
    "    balanced_dfs.append(resampled_df)\n",
    "\n",
    "final_data = pd.concat(balanced_dfs)\n",
    "print(\"Rozkład klas PO zbalansowaniu:\")\n",
    "print(final_data['BuildingCondition'].value_counts())\n",
    "\n",
    "# --- KROK 3: UPROSZCZONE PRZYGOTOWANIE DANYCH DO MODELU ---\n",
    "print(\"\\n--- Krok 3: Uproszczone przygotowanie danych do modelu ---\")\n",
    "numeric_features = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors']\n",
    "categorical_features = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "# Uzupełnianie braków\n",
    "for col in numeric_features:\n",
    "    final_data[col] = pd.to_numeric(final_data[col], errors='coerce').fillna(final_data[col].median())\n",
    "for col in categorical_features:\n",
    "    final_data[col] = final_data[col].fillna(final_data[col].mode()[0])\n",
    "final_data['year'] = pd.to_datetime(final_data['BuiltYear'], errors='coerce').dt.year.fillna(final_data['BuiltYear'].dt.year.median())\n",
    "\n",
    "# Mapowanie etykiet\n",
    "labels = final_data['BuildingCondition'].astype('category')\n",
    "label_mapping = dict(enumerate(labels.cat.categories))\n",
    "y_categorical = to_categorical(labels.cat.codes)\n",
    "\n",
    "# Przygotowanie danych tekstowych\n",
    "max_words, max_len = 10000, 200\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(final_data['Description'])\n",
    "X_text = pad_sequences(tokenizer.texts_to_sequences(final_data['Description']), maxlen=max_len)\n",
    "\n",
    "# ---- RĘCZNE PRZYGOTOWANIE DANYCH TABELARYCZNYCH ----\n",
    "# 1. Skalowanie cech numerycznych\n",
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(final_data[numeric_features + ['year']])\n",
    "\n",
    "# 2. Ręczne kodowanie One-Hot\n",
    "# Ważne: używamy get_dummies z Pandas, jest prostszy\n",
    "X_categorical = pd.get_dummies(final_data[categorical_features])\n",
    "# Zapisujemy nazwy kolumn, aby użyć ich w skrypcie\n",
    "encoded_categorical_columns = X_categorical.columns.tolist()\n",
    "\n",
    "# 3. Łączenie\n",
    "X_tabular = np.concatenate([X_numeric, X_categorical.values], axis=1)\n",
    "\n",
    "# Podział na zbiory\n",
    "X_text_train, X_text_test, X_tabular_train, X_tabular_test, y_train, y_test = train_test_split(\n",
    "    X_text, X_tabular, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9038eb3d-872f-4f34-af88-90fc35161810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tabular_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m1,280,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m49,408\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tabular_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m480\u001b[0m │ tabular_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m6,208\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │             \u001b[38;5;34m260\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,336,356</span> (5.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,336,356\u001b[0m (5.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,336,356</span> (5.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,336,356\u001b[0m (5.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynam trening na zbalansowanych danych...\n",
      "Epoch 1/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 233ms/step - accuracy: 0.6857 - loss: 0.8031 - val_accuracy: 0.9433 - val_loss: 0.2029\n",
      "Epoch 2/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 252ms/step - accuracy: 0.9441 - loss: 0.2148 - val_accuracy: 0.9586 - val_loss: 0.1263\n",
      "Epoch 3/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 258ms/step - accuracy: 0.9546 - loss: 0.1488 - val_accuracy: 0.9633 - val_loss: 0.1027\n",
      "Epoch 4/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 264ms/step - accuracy: 0.9610 - loss: 0.1145 - val_accuracy: 0.9642 - val_loss: 0.0994\n",
      "Epoch 5/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 274ms/step - accuracy: 0.9692 - loss: 0.0864 - val_accuracy: 0.9661 - val_loss: 0.1096\n",
      "Epoch 6/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 284ms/step - accuracy: 0.9702 - loss: 0.0796 - val_accuracy: 0.9670 - val_loss: 0.0969\n",
      "Epoch 7/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 283ms/step - accuracy: 0.9725 - loss: 0.0739 - val_accuracy: 0.9661 - val_loss: 0.0993\n",
      "Epoch 8/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 0.9792 - loss: 0.0573 - val_accuracy: 0.9637 - val_loss: 0.1104\n",
      "Epoch 9/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 283ms/step - accuracy: 0.9773 - loss: 0.0587 - val_accuracy: 0.9656 - val_loss: 0.1035\n",
      "Epoch 10/10\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 290ms/step - accuracy: 0.9820 - loss: 0.0482 - val_accuracy: 0.9647 - val_loss: 0.1287\n"
     ]
    }
   ],
   "source": [
    "# --- BUDOWA I TRENING MODELU ---\n",
    "# Definiujemy architekturę\n",
    "text_input = Input(shape=(max_len,), name='text_input')\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=128)(text_input)\n",
    "lstm_layer = LSTM(64, recurrent_dropout=0.2)(embedding_layer)\n",
    "dropout_lstm = Dropout(0.4)(lstm_layer)\n",
    "\n",
    "tabular_input = Input(shape=(X_tabular_train.shape[1],), name='tabular_input')\n",
    "tabular_dense = Dense(32, activation='relu')(tabular_input)\n",
    "\n",
    "concatenated = Concatenate()([dropout_lstm, tabular_dense])\n",
    "dense1 = Dense(64, activation='relu')(concatenated)\n",
    "dropout_final = Dropout(0.5)(dense1)\n",
    "output = Dense(len(label_mapping), activation='softmax')(dropout_final)\n",
    "\n",
    "model = Model(inputs=[text_input, tabular_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Trening na zbalansowanych danych\n",
    "print(\"\\nRozpoczynam trening na zbalansowanych danych...\")\n",
    "history = model.fit(\n",
    "    [X_text_train, X_tabular_train], y_train,\n",
    "    epochs=10, \n",
    "    batch_size=128,\n",
    "    validation_data=([X_text_test, X_tabular_test], y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3738c9b4-85d7-4338-9e65-1cfa2a1ac141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Keras zapisany jako 'model_lstm_stan.keras'\n",
      "Tokenizer zapisany jako 'tokenizer.json'\n",
      "Preprocessor zapisany jako 'preprocessor.joblib'\n",
      "Mapowanie etykiet zapisane jako 'label_mapping.json'\n",
      "Zapisano listę i kolejność kolumn do pliku: columns_for_prediction.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# --- ZAPIS MODELU I WSZYSTKICH POTRZEBNYCH OBIEKTÓW ---\n",
    "\n",
    "# 1. Zapis modelu Keras\n",
    "model.save('model_lstm_stan.keras')\n",
    "print(\"Model Keras zapisany jako 'model_lstm_stan.keras'\")\n",
    "\n",
    "# 2. Zapis Tokenizera\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer.to_json(), ensure_ascii=False))\n",
    "print(\"Tokenizer zapisany jako 'tokenizer.json'\")\n",
    "\n",
    "# 3. Zapis Preprocesora (ColumnTransformer)\n",
    "# Definiujemy go ponownie, aby mieć pewność\n",
    "numeric_features = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'year']\n",
    "categorical_features = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "preprocessor_to_save = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "# Uczymy go na tych samych danych\n",
    "preprocessor_to_save.fit(final_data[numeric_features + categorical_features])\n",
    "joblib.dump(preprocessor_to_save, 'preprocessor.joblib')\n",
    "print(\"Preprocessor zapisany jako 'preprocessor.joblib'\")\n",
    "\n",
    "# 4. Zapis mapowania etykiet\n",
    "with open('label_mapping.json', 'w') as f:\n",
    "    label_mapping_str_keys = {str(k): v for k, v in label_mapping.items()}\n",
    "    json.dump(label_mapping_str_keys, f)\n",
    "print(\"Mapowanie etykiet zapisane jako 'label_mapping.json'\")\n",
    "\n",
    "# ---- KLUCZOWA ZMIANA: ZAPISUJEMY KOLEJNOŚĆ KOLUMN ----\n",
    "columns_for_prediction = numeric_features + categorical_features\n",
    "joblib.dump(columns_for_prediction, 'columns_for_prediction.joblib')\n",
    "print(f\"Zapisano listę i kolejność kolumn do pliku: columns_for_prediction.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05fb4fa-a6ab-4bc3-9d88-9fd22873c900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ocena modelu na zbiorze testowym ---\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9676 - loss: 0.1128\n",
      "\n",
      "Dokładność na zbiorze testowym: 0.9647\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step\n",
      "\n",
      "Raport klasyfikacji na zbiorze testowym:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "AFTER_RENOVATION       0.47      0.28      0.35        32\n",
      " DEVELOPER_STATE       0.98      1.00      0.99      2000\n",
      "  FOR_RENOVATION       0.50      0.05      0.10        19\n",
      "            GOOD       0.70      0.70      0.70       100\n",
      "\n",
      "        accuracy                           0.96      2151\n",
      "       macro avg       0.66      0.51      0.53      2151\n",
      "    weighted avg       0.96      0.96      0.96      2151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- OCENA MODELU ---\n",
    "print(\"\\n--- Ocena modelu na zbiorze testowym ---\")\n",
    "loss, accuracy = model.evaluate([X_text_test, X_tabular_test], y_test)\n",
    "print(f\"\\nDokładność na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "y_pred_proba = model.predict([X_text_test, X_tabular_test])\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nRaport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_test_labels, y_pred, target_names=list(label_mapping.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd93d797-b8d9-4685-9dd9-d17a0580dad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Rozpoczynam predykcję na całej bazie danych ---\n",
      "\n",
      "Krok 1: Przygotowuję cały zbiór danych do predykcji...\n",
      "Dane wstępnie przygotowane.\n",
      "Krok 2: Transformuję dane tekstowe i tabelaryczne...\n",
      "Transformacja zakończona.\n",
      "Krok 3: Wykonuję predykcje na całym zbiorze...\n",
      "\u001b[1m23774/23774\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 29ms/step\n",
      "Predykcje wykonane.\n",
      "Krok 4: Mapuję wyniki na etykiety tekstowe...\n",
      "Zakończono mapowanie. Nowa kolumna 'Predict_State' została utworzona.\n",
      "Krok 5: Stosuję twarde reguły biznesowe...\n",
      "Reguły zastosowane.\n",
      "\n",
      "Krok 6: Rozpoczynam zapis do pliku: Data_state_LSTM_predicted_full.csv\n",
      "Zapisuję 760765 wierszy i 55 kolumn.\n",
      "\n",
      "Zapisano pełny zbiór danych z predykcjami do pliku: Data_state_LSTM_predicted_full.csv\n"
     ]
    }
   ],
   "source": [
    "# --- FINALNA PREDYKCJA I ZAPIS (WERSJA POPRAWIONA I KOMPLETNA) ---\n",
    "import csv\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"\\n--- Rozpoczynam predykcję na całej bazie danych ---\\n\")\n",
    "\n",
    "# Krok 1: Przygotowanie pełnego zbioru danych (df_full)\n",
    "print(\"Krok 1: Przygotowuję cały zbiór danych do predykcji...\")\n",
    "df_full = df.copy()\n",
    "\n",
    "# Uzupełnianie braków - tak jak w komórce treningowej, aby uniknąć błędów\n",
    "# Najważniejsze: Opis nie może być pusty (NaN)\n",
    "df_full['Description'].fillna('', inplace=True)\n",
    "\n",
    "# Definiujemy cechy, tak jak wcześniej\n",
    "numeric_features_pred = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors']\n",
    "categorical_features_pred = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "\n",
    "# Poprawne uzupełnianie cech numerycznych\n",
    "for col in numeric_features_pred:\n",
    "    # Najpierw konwertujemy całą kolumnę na typ numeryczny\n",
    "    df_full[col] = pd.to_numeric(df_full[col], errors='coerce')\n",
    "    # Dopiero teraz, na numerycznej kolumnie, obliczamy medianę i wypełniamy braki\n",
    "    median_val = df_full[col].median()\n",
    "    df_full[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Uzupełnianie cech kategorycznych\n",
    "for col in categorical_features_pred:\n",
    "    mode_val = df_full[col].mode()[0]\n",
    "    df_full[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Poprawne tworzenie kolumny 'year'\n",
    "# Krok 1: Konwertujemy 'BuiltYear' na typ daty\n",
    "built_year_datetime = pd.to_datetime(df_full['BuiltYear'], errors='coerce')\n",
    "# Krok 2: Z tej przekonwertowanej kolumny wyciągamy rok\n",
    "years = built_year_datetime.dt.year\n",
    "# Krok 3: Obliczamy medianę z poprawnych lat\n",
    "median_year = years.median()\n",
    "# Krok 4: Uzupełniamy braki i przypisujemy do nowej kolumny\n",
    "df_full['year'] = years.fillna(median_year)\n",
    "\n",
    "print(\"Dane wstępnie przygotowane.\")\n",
    "\n",
    "\n",
    "# Krok 2: Użycie zapisanych obiektów do transformacji danych\n",
    "print(\"Krok 2: Transformuję dane tekstowe i tabelaryczne...\")\n",
    "\n",
    "# a) Transformacja danych tekstowych\n",
    "sequences_full = tokenizer.texts_to_sequences(df_full['Description'])\n",
    "X_text_full = pad_sequences(sequences_full, maxlen=max_len)\n",
    "\n",
    "# b) Transformacja danych tabelarycznych\n",
    "# Upewniamy się, że używamy tych samych kolumn, co przy treningu\n",
    "columns_to_use = numeric_features_pred + ['year'] + categorical_features_pred\n",
    "X_tabular_full = preprocessor_to_save.transform(df_full[columns_to_use])\n",
    "print(\"Transformacja zakończona.\")\n",
    "\n",
    "\n",
    "# Krok 3: Wykonanie predykcji\n",
    "print(\"Krok 3: Wykonuję predykcje na całym zbiorze...\")\n",
    "predictions_proba = model.predict([X_text_full, X_tabular_full])\n",
    "# Znajdujemy indeks klasy z najwyższym prawdopodobieństwem\n",
    "predicted_class_indices = np.argmax(predictions_proba, axis=1)\n",
    "print(\"Predykcje wykonane.\")\n",
    "\n",
    "# Krok 4: Zmapowanie wyników z powrotem na etykiety tekstowe\n",
    "print(\"Krok 4: Mapuję wyniki na etykiety tekstowe...\")\n",
    "# Tworzymy odwrotne mapowanie (z numeru na tekst)\n",
    "inverse_label_mapping = {int(k): v for k, v in label_mapping.items()}\n",
    "# Używamy mapowania do przetłumaczenia indeksów na nazwy\n",
    "predicted_conditions = [inverse_label_mapping[i] for i in predicted_class_indices]\n",
    "\n",
    "# Teraz zmienna predicted_conditions istnieje!\n",
    "df_full['Predict_State'] = predicted_conditions\n",
    "print(\"Zakończono mapowanie. Nowa kolumna 'Predict_State' została utworzona.\")\n",
    "\n",
    "# Krok 5: Stosowanie twardych reguł biznesowych\n",
    "print(\"Krok 5: Stosuję twarde reguły biznesowe...\")\n",
    "df_full.loc[df_full['TypeOfMarket'] == 'pierwotny', 'Predict_State'] = 'DEVELOPER_STATE'\n",
    "df_full.loc[pd.to_datetime(df_full['BuiltYear'], errors='coerce').dt.year >= 2024, 'Predict_State'] = 'DEVELOPER_STATE'\n",
    "print(\"Reguły zastosowane.\")\n",
    "\n",
    "# Krok 6: Zapisanie wyników\n",
    "output_filename = 'Data_state_LSTM_predicted_full.csv'\n",
    "print(f\"\\nKrok 6: Rozpoczynam zapis do pliku: {output_filename}\")\n",
    "print(f\"Zapisuję {len(df_full)} wierszy i {len(df_full.columns)} kolumn.\")\n",
    "\n",
    "df_full.to_csv(\n",
    "    output_filename, \n",
    "    index=False, \n",
    "    sep=';', \n",
    "    encoding='utf-8-sig',\n",
    "    quoting=csv.QUOTE_ALL \n",
    ")\n",
    "\n",
    "print(f\"\\nZapisano pełny zbiór danych z predykcjami do pliku: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9193c4db-1ce7-4807-bee4-b68682cd175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tabela porównawcza: Oryginalny stan vs. Predykcja modelu ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleId</th>\n",
       "      <th>BuildingCondition</th>\n",
       "      <th>BuiltYear</th>\n",
       "      <th>Predict_State</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754100</th>\n",
       "      <td>2484616</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>519000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750592</th>\n",
       "      <td>2215863</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>444192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560089</th>\n",
       "      <td>3145430</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>880000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228293</th>\n",
       "      <td>1846351</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>AFTER_RENOVATION</td>\n",
       "      <td>699000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347012</th>\n",
       "      <td>2531206</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2010</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>884000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588409</th>\n",
       "      <td>3225570</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>219000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187686</th>\n",
       "      <td>1516506</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2000</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>850000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392235</th>\n",
       "      <td>2753629</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>580000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424947</th>\n",
       "      <td>2825603</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2021</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>695000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290191</th>\n",
       "      <td>2187030</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>414990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663385</th>\n",
       "      <td>3448853</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86408</th>\n",
       "      <td>593322</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>519000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302202</th>\n",
       "      <td>2249092</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>339000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289650</th>\n",
       "      <td>2184655</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2008</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>404000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99405</th>\n",
       "      <td>714618</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1950</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>319000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517155</th>\n",
       "      <td>3031604</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1910</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>1350000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599367</th>\n",
       "      <td>3255429</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2024</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>380000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298383</th>\n",
       "      <td>2226852</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2025</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>599193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629517</th>\n",
       "      <td>3342303</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1997</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>780000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480472</th>\n",
       "      <td>2943264</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>DEVELOPER_STATE</td>\n",
       "      <td>409839.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SaleId BuildingCondition BuiltYear     Predict_State      Price\n",
       "754100  2484616              NULL      2024   DEVELOPER_STATE   519000.0\n",
       "750592  2215863              NULL      NULL   DEVELOPER_STATE   444192.0\n",
       "560089  3145430              NULL      NULL              GOOD   880000.0\n",
       "228293  1846351              NULL      NULL  AFTER_RENOVATION   699000.0\n",
       "347012  2531206              NULL      2010   DEVELOPER_STATE   884000.0\n",
       "588409  3225570              NULL      NULL   DEVELOPER_STATE   219000.0\n",
       "187686  1516506              NULL      2000   DEVELOPER_STATE   850000.0\n",
       "392235  2753629              NULL      NULL   DEVELOPER_STATE   580000.0\n",
       "424947  2825603              NULL      2021   DEVELOPER_STATE   695000.0\n",
       "290191  2187030              NULL      NULL   DEVELOPER_STATE   414990.0\n",
       "663385  3448853              NULL      NULL   DEVELOPER_STATE   350000.0\n",
       "86408    593322              NULL      2024   DEVELOPER_STATE   519000.0\n",
       "302202  2249092              NULL      NULL   DEVELOPER_STATE   339000.0\n",
       "289650  2184655              NULL      2008              GOOD   404000.0\n",
       "99405    714618              NULL      1950   DEVELOPER_STATE   319000.0\n",
       "517155  3031604              NULL      1910              GOOD  1350000.0\n",
       "599367  3255429              NULL      2024   DEVELOPER_STATE   380000.0\n",
       "298383  2226852              NULL      2025   DEVELOPER_STATE   599193.0\n",
       "629517  3342303              NULL      1997              GOOD   780000.0\n",
       "480472  2943264              NULL      NULL   DEVELOPER_STATE   409839.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Tabela porównawcza: Oryginalny stan vs. Predykcja modelu ---\")\n",
    "\n",
    "# Wybieramy tylko interesujące nas kolumny\n",
    "comparison_df = df_full[['SaleId', 'BuildingCondition','BuiltYear', 'Predict_State', 'Price']].copy()\n",
    "\n",
    "# Wyświetlamy 20 losowych wierszy, aby zobaczyć różne przypadki\n",
    "# Wyświetlamy tylko te, gdzie oryginalny 'BuildingCondition' nie był pusty, aby porównanie miało sens\n",
    "meaningful_comparison = comparison_df.dropna(subset=['BuildingCondition'])\n",
    "\n",
    "if not meaningful_comparison.empty:\n",
    "    # Jeśli są jakieś wiersze do porównania, wyświetl próbkę\n",
    "    display(meaningful_comparison.sample(min(20, len(meaningful_comparison))))\n",
    "else:\n",
    "    # Jeśli wszystkie oryginalne stany były puste, wyświetl próbkę ogólnych predykcji\n",
    "    print(\"Nie znaleziono wierszy z oryginalną wartością 'BuildingCondition' do porównania.\")\n",
    "    print(\"Wyświetlam ogólną próbkę predykcji:\")\n",
    "    display(comparison_df.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945659ff-1144-4748-8ce7-c2a53e505ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
