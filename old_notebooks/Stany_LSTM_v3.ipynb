{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172fa98d-b25c-4b46-b1aa-9e684d5b2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ai\\AppData\\Local\\Temp\\ipykernel_12672\\1614966263.py:104: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  years = pd.to_datetime(full['BuiltYear'], errors='coerce').dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Balans klas przed treningiem ===\n",
      "                   count  percent\n",
      "BuildingCondition                \n",
      "AFTER_RENOVATION   22000    25.14\n",
      "DEVELOPER_STATE    22000    25.14\n",
      "FOR_RENOVATION     21513    24.58\n",
      "GOOD               22000    25.14\n",
      "\n",
      "Class weights: {0: 0.9944602272727273, 1: 0.9944602272727273, 2: 1.0169959325973272, 3: 0.9944602272727273}\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: konfiguracja, wczytanie i przygotowanie danych (id. z v2, bez zmian merytorycznych)\n",
    "\n",
    "import os, csv, io, re, json, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 4 źródła (każdy plik = jedna etykieta docelowa)\n",
    "FILES = {\n",
    "    'sf_after_renovation.csv': 'AFTER_RENOVATION',\n",
    "    'sf_developer_state.csv' : 'DEVELOPER_STATE',\n",
    "    'sf_for_renovation.csv'  : 'FOR_RENOVATION',\n",
    "    'sf_good.csv'            : 'GOOD',\n",
    "}\n",
    "\n",
    "# Wymagane przez model pola (zgodnie z notebookiem trenowania)\n",
    "REQUIRED_TEXT = ['Description']\n",
    "REQUIRED_NUM  = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors']\n",
    "REQUIRED_CAT  = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "REQUIRED_DT   = ['BuiltYear']  # źródło kolumny 'year'\n",
    "REQUIRED_ALL  = REQUIRED_TEXT + REQUIRED_NUM + REQUIRED_CAT + REQUIRED_DT\n",
    "\n",
    "# UWAGA: pliki źródłowe mają stałą kolejność kolumn w rekordach CSV.\n",
    "# Na podstawie diagnostyki i próbek mapujemy pozycje -> nazwy:\n",
    "# idx: 4=Description, 5=Area, 6=Price, 11=NumberOfRooms, 12=BuiltYear,\n",
    "# 14=BuildingType, 16=OfferFrom, 17=Floor, 18=Floors, 19=TypeOfMarket, 15=etykieta źródłowa\n",
    "IDX_MAP = {\n",
    "    'Description':    4,\n",
    "    'Area':           5,\n",
    "    'Price':          6,\n",
    "    'NumberOfRooms': 11,\n",
    "    'BuiltYear':     12,\n",
    "    'BuildingType':  14,\n",
    "    'OfferFrom':     16,\n",
    "    'Floor':         17,\n",
    "    'Floors':        18,\n",
    "    'TypeOfMarket':  19,\n",
    "}\n",
    "IDX_LABEL = 15  # zawiera nazwę stanu w rekordach; dla pewności nadpisujemy nazwą pliku\n",
    "\n",
    "# Parser wymuszający prawidłowe dzielenie po przecinku i cudzysłowie, z escape'ami\n",
    "def robust_read_records(path, encoding_candidates=('utf-8-sig','utf-8','cp1250','latin1')):\n",
    "    last_err = None\n",
    "    for enc in encoding_candidates:\n",
    "        try:\n",
    "            rows = []\n",
    "            with open(path, 'r', encoding=enc, errors='replace', newline='') as f:\n",
    "                reader = csv.reader(f, delimiter=',', quotechar='\"', escapechar='\\\\')\n",
    "                for row in reader:\n",
    "                    if not row or (len(row) == 1 and not str(row).strip()):\n",
    "                        continue\n",
    "                    rows.append(row)\n",
    "            if not rows:\n",
    "                continue\n",
    "            median_len = int(np.median([len(r) for r in rows]))\n",
    "            if median_len < 10:\n",
    "                continue\n",
    "            return rows\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err:\n",
    "        raise last_err\n",
    "    raise RuntimeError(f'Unable to parse CSV: {path}')\n",
    "\n",
    "def extract_required_df(rows, force_label):\n",
    "    sel = {}\n",
    "    for name, idx in IDX_MAP.items():\n",
    "        sel[name] = [(r[idx] if len(r) > idx else None) for r in rows]\n",
    "    labels = [force_label for _ in rows]\n",
    "    out = pd.DataFrame(sel)\n",
    "    out['BuildingCondition'] = labels\n",
    "    return out\n",
    "\n",
    "frames = []\n",
    "for path, label in FILES.items():\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'Brak pliku: {path}')\n",
    "    rows   = robust_read_records(path)\n",
    "    df_part= extract_required_df(rows, force_label=label)\n",
    "    frames.append(df_part)\n",
    "\n",
    "full = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# --- CZYSZCZENIE, TYPY, CECHY WTÓRNE ---\n",
    "\n",
    "# Tekst\n",
    "full['Description'] = full['Description'].fillna('').astype(str)\n",
    "\n",
    "# Numeryczne\n",
    "for col in ['Area','Price','NumberOfRooms','Floor','Floors']:\n",
    "    full[col] = pd.to_numeric(full[col], errors='coerce')\n",
    "\n",
    "# Rok budowy -> year (liczba całkowita)\n",
    "years = pd.to_datetime(full['BuiltYear'], errors='coerce').dt.year\n",
    "if years.isna().all():\n",
    "    years = pd.to_numeric(full['BuiltYear'], errors='coerce')\n",
    "full['year'] = years\n",
    "full['year'] = full['year'].fillna(full['year'].median())\n",
    "\n",
    "# Kategoryczne\n",
    "for col in ['BuildingType','OfferFrom','TypeOfMarket']:\n",
    "    full[col] = full[col].fillna('unknown').astype(str).str.strip().str.lower()\n",
    "\n",
    "def norm_market(v):\n",
    "    v = (v or '').lower()\n",
    "    if 'pierwot' in v: return 'pierwotny'\n",
    "    if 'wtór' in v or 'wtorn' in v: return 'wtórny'\n",
    "    return v if v else 'unknown'\n",
    "full['TypeOfMarket'] = full['TypeOfMarket'].apply(norm_market)\n",
    "\n",
    "# --- BALANS KLAS (informacyjnie) ---\n",
    "counts = full['BuildingCondition'].value_counts(dropna=False)\n",
    "perc   = (counts / len(full) * 100).round(2)\n",
    "balance= pd.DataFrame({'count': counts, 'percent': perc}).sort_index()\n",
    "print(\"\\n=== Balans klas przed treningiem ===\")\n",
    "print(balance)\n",
    "\n",
    "# --- PODZIAŁ I PRZYGOTOWANIE WEJŚĆ ---\n",
    "\n",
    "label_names = ['AFTER_RENOVATION','DEVELOPER_STATE','FOR_RENOVATION','GOOD']\n",
    "label_to_idx = {name: i for i, name in enumerate(label_names)}\n",
    "y_idx = full['BuildingCondition'].map(label_to_idx).astype(int).values\n",
    "y = to_categorical(y_idx, num_classes=len(label_names))\n",
    "\n",
    "# Tekst\n",
    "max_words, max_len = 10000, 200\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"\")\n",
    "tokenizer.fit_on_texts(full['Description'].astype(str))\n",
    "X_text = pad_sequences(tokenizer.texts_to_sequences(full['Description'].astype(str)), maxlen=max_len)\n",
    "\n",
    "# Tabelaryczne\n",
    "numeric_features     = ['Area', 'Price', 'NumberOfRooms', 'Floor', 'Floors', 'year']\n",
    "categorical_features = ['BuildingType', 'OfferFrom', 'TypeOfMarket']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "X_tabular = preprocessor.fit_transform(full[numeric_features + categorical_features])\n",
    "\n",
    "# Train/test split ze stratą po klasie\n",
    "X_text_train, X_text_test, X_tab_train, X_tab_test, y_train, y_test, y_idx_train, y_idx_test = train_test_split(\n",
    "    X_text, X_tabular, y, y_idx, test_size=0.2, random_state=42, stratify=y_idx\n",
    ")\n",
    "\n",
    "# Wagi klas (dla porządku, mimo że rozkład jest wyrównany)\n",
    "classes = np.unique(y_idx_train)\n",
    "cw = compute_class_weight(class_weight='balanced', classes=classes, y=y_idx_train)\n",
    "class_weight = {int(c): float(w) for c, w in zip(classes, cw)}\n",
    "print('\\nClass weights:', class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e73bc9-0c3d-4c0f-81c6-618613f68d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tabular_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8220</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,072</span> │ tabular_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m1,280,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m49,408\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ tabular_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8220\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                 │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │         \u001b[38;5;34m263,072\u001b[0m │ tabular_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m6,208\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │             \u001b[38;5;34m260\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,598,948</span> (6.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,598,948\u001b[0m (6.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,598,948</span> (6.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,598,948\u001b[0m (6.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rozpoczynam trening na nowych danych (20 epok + callbacki)...\n",
      "Epoch 1/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.4345 - loss: 1.2044\n",
      "Epoch 1: val_loss improved from inf to 1.04479, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 506ms/step - accuracy: 0.4346 - loss: 1.2043 - val_accuracy: 0.5445 - val_loss: 1.0448 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.5605 - loss: 1.0295\n",
      "Epoch 2: val_loss improved from 1.04479 to 0.97104, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 526ms/step - accuracy: 0.5605 - loss: 1.0295 - val_accuracy: 0.5789 - val_loss: 0.9710 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - accuracy: 0.5164 - loss: 1.1323\n",
      "Epoch 3: val_loss did not improve from 0.97104\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 538ms/step - accuracy: 0.5164 - loss: 1.1323 - val_accuracy: 0.5716 - val_loss: 0.9947 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.6160 - loss: 0.9714\n",
      "Epoch 4: val_loss improved from 0.97104 to 0.84954, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 543ms/step - accuracy: 0.6161 - loss: 0.9714 - val_accuracy: 0.7133 - val_loss: 0.8495 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.6845 - loss: 0.9186\n",
      "Epoch 5: val_loss did not improve from 0.84954\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 534ms/step - accuracy: 0.6844 - loss: 0.9187 - val_accuracy: 0.6052 - val_loss: 0.9834 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.6517 - loss: 0.9420\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.84954\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 566ms/step - accuracy: 0.6517 - loss: 0.9419 - val_accuracy: 0.6935 - val_loss: 0.8554 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.7087 - loss: 0.8542\n",
      "Epoch 7: val_loss improved from 0.84954 to 0.83740, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 570ms/step - accuracy: 0.7087 - loss: 0.8542 - val_accuracy: 0.7047 - val_loss: 0.8374 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.7056 - loss: 0.8517\n",
      "Epoch 8: val_loss did not improve from 0.83740\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 538ms/step - accuracy: 0.7056 - loss: 0.8517 - val_accuracy: 0.6885 - val_loss: 0.8582 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.6933 - loss: 0.8504\n",
      "Epoch 9: val_loss improved from 0.83740 to 0.83094, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 564ms/step - accuracy: 0.6933 - loss: 0.8504 - val_accuracy: 0.7057 - val_loss: 0.8309 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.7310 - loss: 0.8142\n",
      "Epoch 10: val_loss improved from 0.83094 to 0.81085, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 546ms/step - accuracy: 0.7310 - loss: 0.8142 - val_accuracy: 0.7246 - val_loss: 0.8109 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.7473 - loss: 0.7902\n",
      "Epoch 11: val_loss improved from 0.81085 to 0.80298, saving model to model_best.keras\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 554ms/step - accuracy: 0.7473 - loss: 0.7902 - val_accuracy: 0.7301 - val_loss: 0.8030 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.7571 - loss: 0.7772\n",
      "Epoch 12: val_loss did not improve from 0.80298\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 555ms/step - accuracy: 0.7571 - loss: 0.7772 - val_accuracy: 0.6986 - val_loss: 0.8373 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.7427 - loss: 0.7853\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.80298\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 548ms/step - accuracy: 0.7427 - loss: 0.7853 - val_accuracy: 0.7031 - val_loss: 0.8290 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.7393 - loss: 0.7795\n",
      "Epoch 14: val_loss did not improve from 0.80298\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 559ms/step - accuracy: 0.7393 - loss: 0.7795 - val_accuracy: 0.7235 - val_loss: 0.8079 - learning_rate: 2.5000e-04\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: architektura (bez zmian względem v2), kompilacja i trenowanie z 20 epokami + callbacki\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Architektura\n",
    "text_input = Input(shape=(max_len,), name='text_input')\n",
    "embedding_layer = Embedding(input_dim=max_words, output_dim=128)(text_input)\n",
    "lstm_layer = LSTM(64, recurrent_dropout=0.2)(embedding_layer)\n",
    "dropout_lstm = Dropout(0.4)(lstm_layer)\n",
    "\n",
    "tabular_input = Input(shape=(X_tab_train.shape[1],), name='tabular_input')\n",
    "tabular_dense = Dense(32, activation='relu')(tabular_input)\n",
    "\n",
    "concatenated  = Concatenate()([dropout_lstm, tabular_dense])\n",
    "dense1        = Dense(64, activation='relu')(concatenated)\n",
    "dropout_final = Dropout(0.5)(dense1)\n",
    "output        = Dense(len(label_names), activation='softmax')(dropout_final)\n",
    "\n",
    "model = Model(inputs=[text_input, tabular_input], outputs=output)\n",
    "model.summary()\n",
    "\n",
    "# Kompilacja: label smoothing + Adam lr=1e-3\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacki: EarlyStopping, ReduceLROnPlateau, Checkpoint\n",
    "es  = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "ckp = ModelCheckpoint('model_best.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "print(\"\\nRozpoczynam trening na nowych danych (20 epok + callbacki)...\")\n",
    "history = model.fit(\n",
    "    [X_text_train, X_tab_train], y_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=([X_text_test, X_tab_test], y_test),\n",
    "    callbacks=[es, rlr, ckp],\n",
    "    class_weight=class_weight  # pozostawione dla spójności\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddce268-7936-4975-b351-764ab10db295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 82ms/step - accuracy: 0.7282 - loss: 0.8022\n",
      "\n",
      "Dokładność na zbiorze testowym: 0.7301\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 68ms/step\n",
      "\n",
      "Raport klasyfikacji na zbiorze testowym:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "AFTER_RENOVATION       0.59      0.75      0.66      4400\n",
      " DEVELOPER_STATE       0.91      0.89      0.90      4400\n",
      "  FOR_RENOVATION       0.80      0.73      0.76      4303\n",
      "            GOOD       0.67      0.55      0.61      4400\n",
      "\n",
      "        accuracy                           0.73     17503\n",
      "       macro avg       0.74      0.73      0.73     17503\n",
      "    weighted avg       0.74      0.73      0.73     17503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: ocena na teście\n",
    "\n",
    "loss, accuracy = model.evaluate([X_text_test, X_tab_test], y_test)\n",
    "print(f\"\\nDokładność na zbiorze testowym: {accuracy:.4f}\")\n",
    "\n",
    "# Raport per klasa\n",
    "y_pred_proba = model.predict([X_text_test, X_tab_test])\n",
    "y_pred       = np.argmax(y_pred_proba, axis=1)\n",
    "y_true       = np.argmax(y_test, axis=1)\n",
    "print(\"\\nRaport klasyfikacji na zbiorze testowym:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392eedf4-c338-4ca1-8429-4db113af5bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zapisano: model_lstm_stan.keras, tokenizer.json, preprocessor.joblib, label_mapping.json, columns_for_prediction.joblib\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: zapis artefaktów (bez zmian względem v2)\n",
    "\n",
    "import joblib, json\n",
    "\n",
    "# Model z przywróconymi najlepszymi wagami (EarlyStopping) + checkpoint na val_loss\n",
    "model.save('model_lstm_stan.keras')\n",
    "\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer.to_json(), ensure_ascii=False))\n",
    "\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "\n",
    "label_mapping = {i: name for i, name in enumerate(label_names)}\n",
    "with open('label_mapping.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump({str(k): v for k, v in label_mapping.items()}, f, ensure_ascii=False)\n",
    "\n",
    "columns_for_prediction = numeric_features + categorical_features\n",
    "joblib.dump(columns_for_prediction, 'columns_for_prediction.joblib')\n",
    "\n",
    "print(\"Zapisano: model_lstm_stan.keras, tokenizer.json, preprocessor.joblib, label_mapping.json, columns_for_prediction.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26884c-15e3-47eb-9720-511a7fbe8fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
